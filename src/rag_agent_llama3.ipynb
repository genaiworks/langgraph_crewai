{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -U langchain-nomic langchain_community tiktoken langchainhub chromadb langchain langgraph tavily-python gpt4all firecreawl-py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install firecrawl-py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"LANGCHAIN_API_KEY\"] = \"ls__\"\n",
    "os.environ[\"LANGCHAIN_ENDPOINT\"] = \"https://api.smith.langchain.com\"\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "local_llm ='llama3'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "local_llm='llama3:latest'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_community.document_loaders import FireCrawlLoader\n",
    "from langchain_community.embeddings import GPT4AllEmbeddings\n",
    "from langchain_community.vectorstores.utils import filter_complex_metadata\n",
    "from langchain.docstore.document import Document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -U langchain-nomic langchain_community tiktoken firecrawl-py gpt4all langchainhub chromadb langchain langgraph tavily-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "urls =[\n",
    "\"https://www.ai-jason.com/learning-ai/how-to-reduce-llm-cost\",\n",
    "\"https://www.ai-jason.com/learning-ai/gpt5-llm\",\n",
    "\"https://www.ai-jason.com/learning-ai/ai-agent-tutorial-2\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = [FireCrawlLoader(api_key=\"fc-9d9edbfedf674d2b8cedc83199db0192\", url=url, mode=\"scrape\").load() for url in urls]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split the documents into chunks\n",
    "docs_list = [item for sublist in docs for item in sublist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "_result = []\n",
    "for sublist in docs:\n",
    "    for item in sublist:\n",
    "        _result.append(item)\n",
    "# That's really all it is, except that _result doesn't have a name and is appended to implicitly. \n",
    "# The outer loop iterates over the three lists of l and for each of those lists, \n",
    "# the inner loop iterates over the items in that list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='[AI JASON](/)\\n\\nCategories\\n\\n\\ue80f\\n\\n[AI Agent](/ai/ai-agent)\\n\\n[AI Automation Tutorials](/ai/ai-automation-tutorials)\\n\\n[Langchain Tutorials](/ai/langchain-tutorial)\\n\\n[Auto GPT Tutorials](/ai/auto-gpt-tutorial)\\n\\n[Contact](/contact)\\n\\n[\\ue82e](https://www.youtube.com/@AIJason-oc8wb)\\n[\\ue829](https://twitter.com/jasonzhou1993)\\n[\\ue819](https://www.linkedin.com/in/jasonzhoudesign/)\\n\\n[AI Agent](/ai/ai-agent)\\n\\nHow to reduce 78%+ of LLM Cost\\n==============================\\n\\nHow to reduce 78%+ of LLM Cost\\n==============================\\n\\nAre you building AI agents or using chatGPT? If so, you may be facing the challenge of high costs associated with large language models (LLM). In this article, we will explore effective strategies to reduce LLM costs by up to 78%. Let\\'s dive in!\\n\\n\\u200d\\n\\n1\\\\. Change Model\\n----------------\\n\\nOne effective way to reduce LLM costs is to change the model you are using. Different models have different costs associated with them. For example, GPT-4 is the most powerful but also the most expensive model, while Mistro 7B is significantly cheaper. By using a smaller model for specific tasks and reserving the more expensive model for complex questions, you can achieve significant cost savings.\\n\\n![](https://assets-global.website-files.com/647a9c825f099afe643b5c78/65bedacac82767caefbdf0a0_1.jpg)\\n\\n2\\\\. Large Language Model Router\\n-------------------------------\\n\\nThe concept of a large language model router involves using a cascade of models to handle different types of questions. Cheaper models are used first, and if they are unable to provide a satisfactory answer, the question is passed on to a more expensive model. This approach leverages the significant cost difference between models and can result in substantial cost savings.\\n\\n![](https://assets-global.website-files.com/647a9c825f099afe643b5c78/65bedae566010ad14fe382cd_llm%20router.jpg)\\n\\n3\\\\. Multi-Agent Setup\\n---------------------\\n\\nAnother strategy is to set up multiple agents, each using a different model. The first agent attempts to complete the task using a cheaper model, and if it fails, the next agent is invoked. By using this multi-agent setup, you can achieve similar or even better success rates while significantly reducing costs.\\n\\n![](https://assets-global.website-files.com/647a9c825f099afe643b5c78/65bedaefa7461fca4f82df51_autogen.jpg)\\n\\n4\\\\. LLM Lingua\\n--------------\\n\\nLLM Lingua is a method introduced by Microsoft that focuses on optimizing the input and output of large language models. By removing unnecessary tokens and words from the input, you can significantly reduce the cost of running the model. This method is particularly effective for tasks such as summarization or answering specific questions based on a transcript.\\n\\n![](https://assets-global.website-files.com/647a9c825f099afe643b5c78/65bedaf791724343e65da125_llm%20lingua.jpg)\\n\\n5\\\\. Optimize Agent Memory\\n-------------------------\\n\\nOptimizing agent memory is another way to reduce LLM costs. By carefully managing the amount of conversation history stored in memory, you can minimize the number of tokens required for each interaction. This can lead to significant cost savings, especially when dealing with long conversations.\\n\\n![](https://assets-global.website-files.com/647a9c825f099afe643b5c78/65bedb03355b5d49f9ac7f8e_memory%20opt.jpg)\\n\\n6\\\\. Observability\\n-----------------\\n\\nHaving a deep understanding of the cost patterns in your LLM application is crucial for effective cost optimization. By using observability platforms like L Smith, you can monitor and log the cost for each large language model. This allows you to identify areas where costs can be optimized and make informed decisions to reduce overall expenses.\\n\\nBy implementing these strategies, you can reduce LLM costs by up to 78% or more. Remember, reducing costs while maintaining performance and user experience is a critical skill for AI startups. Stay proactive and continuously optimize your LLM usage to maximize efficiency and profitability.\\n\\n\\u200d\\n\\nGet free HubSpot AI For Marketers Course: [https://clickhubspot.com/xut](https://clickhubspot.com/xut)\\n\\nðŸ”— Links\\n\\n*   Follow me on twitter: [https://twitter.com/jasonzhou1993](https://twitter.com/jasonzhou1993)\\n    \\n*   Join my AI email list: [https://crafters.ai/](https://crafters.ai/)\\n    \\n*   My discord: [https://discord.gg/eZXprSaCDE](https://discord.gg/eZXprSaCDE)\\n    \\n*   Inbox Agent: [https://www.youtube.com/watch?v=Jv\\\\_e6Rt4vWE&t=23s&ab\\\\_channel=AIJason](https://www.youtube.com/watch?v=Jv_e6Rt4vWE&t=23s&ab_channel=AIJason)\\n    \\n*   Research Agent: [https://www.youtube.com/watch?v=ogQUlS7CkYA&t=299s&ab\\\\_channel=AIJason](https://www.youtube.com/watch?v=ogQUlS7CkYA&t=299s&ab_channel=AIJason)\\n    \\n*   James Brigg on Agent Memory: [https://www.pinecone.io/learn/series/langchain/langchain-conversational-memory/](https://www.pinecone.io/learn/series/langchain/langchain-conversational-memory/)\\n    \\n*   Another video about details for LLM cost tracking: [https://www.youtube.com/watch?v=Alb2kjUzpZ8&ab\\\\_channel=LearnfromOpenSourcewithElie](https://www.youtube.com/watch?v=Alb2kjUzpZ8&ab_channel=LearnfromOpenSourcewithElie)\\n    \\n\\n\\u200d\\n\\nFrequently Asked Questions\\n--------------------------\\n\\n### Q: How can I determine which model is the most cost-effective for my AI application?\\n\\nA: To determine the most cost-effective model for your AI application, you should consider the specific tasks and requirements of your application. Evaluate the performance and cost trade-offs of different models and choose the one that best fits your needs.\\n\\n### Q: Are there any open-source solutions available for large language model routing?\\n\\nA: While there are no specific open-source solutions for large language model routing, you can explore frameworks like Hugging Face\\'s Hugging GPT, which allows you to build your own routing logic using a large language model as a controller.\\n\\n### Q: How often should I monitor and optimize my LLM costs?\\n\\nA: It is recommended to monitor and optimize your LLM costs regularly, especially as your usage and user base grow. Keep track of cost patterns, identify areas for improvement, and implement cost optimization strategies accordingly.\\n\\n### Q: Can I reduce LLM costs without compromising performance?\\n\\nA: Yes, it is possible to reduce LLM costs without compromising performance. By carefully selecting the right models for specific tasks, optimizing agent memory, and using techniques like LLM Lingua, you can achieve cost savings while maintaining high performance and user experience.\\n\\n### Q: Are there any other cost optimization methods for LLM that I should be aware of?\\n\\nA: While the methods mentioned in this article are effective for reducing LLM costs, there may be other innovative approaches and techniques available. Stay updated with the latest research and developments in the field to discover new cost optimization methods.\\n\\nRelated articles\\n----------------\\n\\n[Browse all articles](/)\\n\\n[AI Agent\\\\\\n\\\\\\n### GPT5 unlocks LLM System 2 Thinking?\\\\\\n\\\\\\n![GPT5 unlocks LLM System 2 Thinking?\\\\\\n](https://assets-global.website-files.com/647a9c825f099afe643b5c78/65bedd7f060ee7802639f834_tiktok%20(2).jpg)](/learning-ai/gpt5-llm)\\n\\n[AI Agent\\\\\\n\\\\\\n### Research agent 3.0 - Build a group of AI researchers - Step by Step Tutorial\\\\\\n\\\\\\n![Research agent 3.0 - Build a group of AI researchers - Step by Step Tutorial](https://assets-global.website-files.com/647a9c825f099afe643b5c78/65bedeabdecca18351fc45d0_tiktok%20(3).jpg)](/learning-ai/how-to-build-ai-agent-tutorial-3)\\n\\n[AI Agent\\\\\\n\\\\\\n### How to Build Agent workforce Tutorial- AI agent manages community 24/7\\\\\\n\\\\\\n![How to Build Agent workforce Tutorial- AI agent manages community 24/7](https://assets-global.website-files.com/647a9c825f099afe643b5c78/65bee17260bcfa83d917651f_tiktok%20(6).jpg)](/learning-ai/ai-agent-tutorial-2)\\n\\n### Need help building your AI apps?\\n\\nI can help you on building AI apps or give trainings\\n\\n[Tell me about your AI app ideas](mailto:jason.zhou.design@gmail.com)\\n\\n[\\ue82e](https://www.youtube.com/@AIJason-oc8wb)\\n[\\ue829](https://twitter.com/jasonzhou1993)\\n[\\ue819](https://www.linkedin.com/in/jasonzhoudesign/)\\n\\nAI Jason\\n\\n100K subscribers\\n\\n[The REAL cost of LLM (And How to reduce 78%+ of Cost)](https://www.youtube.com/watch?v=lHxl5SchjPA)\\n\\nAI Jason\\n\\nSearch\\n\\nInfo\\n\\nShopping\\n\\nTap to unmute\\n\\nIf playback doesn\\'t begin shortly, try restarting your device.\\n\\nShare\\n\\nInclude playlist\\n\\nAn error occurred while retrieving sharing information. Please try again later.\\n\\nWatch later\\n\\nShare\\n\\nCopy link\\n\\nWatch on\\n\\n0:00\\n\\n/ â€¢Live\\n\\nâ€¢\\n\\n[](https://www.youtube.com/watch?v=lHxl5SchjPA \"Watch on YouTube\")', metadata={'title': 'How to reduce 78%+ of LLM Cost', 'description': 'AI Agent, Real cost of LLM', 'ogTitle': 'How to reduce 78%+ of LLM Cost', 'ogDescription': 'AI Agent, Real cost of LLM', 'ogImage': 'https://assets-global.website-files.com/647a9c825f099afe643b5c78/65bedbda9969f366afdfad25_tiktok%20(1).jpg', 'ogLocaleAlternate': [], 'sourceURL': 'https://www.ai-jason.com/learning-ai/how-to-reduce-llm-cost'}),\n",
       " Document(page_content='[AI JASON](/)\\n\\nCategories\\n\\n\\ue80f\\n\\n[AI Agent](/ai/ai-agent)\\n\\n[AI Automation Tutorials](/ai/ai-automation-tutorials)\\n\\n[Langchain Tutorials](/ai/langchain-tutorial)\\n\\n[Auto GPT Tutorials](/ai/auto-gpt-tutorial)\\n\\n[Contact](/contact)\\n\\n[\\ue82e](https://www.youtube.com/@AIJason-oc8wb)\\n[\\ue829](https://twitter.com/jasonzhou1993)\\n[\\ue819](https://www.linkedin.com/in/jasonzhoudesign/)\\n\\n[AI Agent](/ai/ai-agent)\\n\\nGPT5 unlocks LLM System 2 Thinking?\\n===================================\\n\\nGPT5 unlocks LLM System 2 Thinking?\\n===================================\\n\\nAI has come a long way in recent years, with large language models (LLMs) like GPT-4 impressing us with their ability to generate text. However, these models primarily rely on system one thinking, which is fast and intuitive but lacks the ability to break down complex problems into smaller steps and explore different options. This limitation has led researchers to focus on developing GPT-5 with enhanced reasoning abilities and reliability.\\n\\nThe Two Modes of Thinking\\n-------------------------\\n\\nIn his book \"Thinking, Fast and Slow,\" Daniel Kahneman introduces the concept of two modes of thinking: system one and system two. System one thinking is our fast, intuitive brain that quickly provides answers based on memorized information. On the other hand, system two thinking is slower but more rational, requiring us to take time, calculate, and analyze before arriving at an answer.\\n\\nSimilarly, large language models like GPT-4 primarily rely on system one thinking. They predict the best next words based on the sequence of words they have seen before, without truly understanding the complex problems they are trying to solve.\\n\\n![](https://assets-global.website-files.com/img/image-placeholder.svg)\\n\\n\\u200d\\n\\nThe Limitations of GPT-4\\n------------------------\\n\\nGPT-4, despite its impressive capabilities, lacks system two thinking. It cannot break down complex tasks into smaller steps or explore different options. It simply generates text based on patterns it has learned from training data. This limitation becomes evident when GPT-4 is faced with complex problems that require deeper analysis and reasoning.\\n\\nFor example, in a video by Veritasium, college students were asked seemingly simple questions like the time it takes for the Earth to go around the Sun. Many of them answered incorrectly because they relied on system one thinking, providing automatic intuitive answers without truly considering the question.\\n\\nLarge language models like GPT-4 face a similar challenge. They lack the ability to think critically and break down complex problems into smaller, manageable steps. This is where GPT-5 comes in.\\n\\nThe Promise of GPT-5\\n--------------------\\n\\nGPT-5 aims to enhance the reasoning abilities of large language models and introduce system two thinking. OpenAI\\'s Sam Altman mentioned in an interview with Bill Gates that the key milestones for GPT-5 will be around reasoning ability and reliability.\\n\\nCurrently, GPT-4 can reason in extremely limited ways and lacks reliability. It may provide correct answers, but it doesn\\'t always know which answer is the best. GPT-5 aims to improve this by increasing reliability and enhancing reasoning abilities.\\n\\nAltman also mentioned the possibility of GPT-5 being able to solve complex math equations by applying transformations an arbitrary number of times. This would require a more complex control logic for reasoning, going beyond what is currently possible with GPT-4.\\n\\nHowever, simply improving the model itself is not enough. There are ways to enforce system two thinking in large language models today, even with GPT-4.\\n\\nPromoting System 2 Thinking in Large Language Models\\n----------------------------------------------------\\n\\nThere are two common strategies to promote system two thinking in large language models: prompt engineering and communicative agents.\\n\\n### Prompt Engineering\\n\\nPrompt engineering is a simple and common method to guide large language models towards system two thinking. One approach is the \"chain of thought,\" where a sentence is inserted step by step before the model generates any text. This forces the model to break down the problem into smaller steps and think through each one.\\n\\nAnother approach is to provide a few short prompt examples instead of a step-by-step process. These examples guide the model towards thinking through different steps and considering multiple possibilities.\\n\\nWhile prompt engineering can be effective in promoting system two thinking, it has limitations. It often restricts the model to consider only one possibility and may not explore diverse options, similar to how humans approach creative problem-solving.\\n\\nTo address this limitation, more advanced prompting tactics like self-consistency with chain of thought (SCCOT) have been proposed. SCCOT involves running the chain of thought process multiple times and reviewing and voting on the most reasonable answers. This allows for some exploration of different options but requires more implementation effort.\\n\\nAnother advanced prompting tactic is the tree of sorts, which simulates a tree search to explore different options and paths. It keeps track of all the paths explored and allows for backtracking if the current path doesn\\'t lead to the desired outcome. However, implementing the tree of sorts is complex and requires significant implementation effort.\\n\\n### Communicative Agents\\n\\nCommunicative agents provide an elegant solution to promote system two thinking in large language models. These are multi-agent setups where users can define different agents and simulate conversations between them. The agents can reflect and spot flaws in each other\\'s perspectives and thinking processes.\\n\\nCommunicative agents have shown promise in enhancing system two thinking. They allow for dedicated agents to review and critique the model\\'s answers, identifying flaws and providing feedback. This collaborative approach mimics how humans solve complex problems by exploring multiple options and learning from each other.\\n\\nSetting up communicative agents can be done using various frameworks like ChatGPT, MetaGPT, Autogen, and Crew AI. These frameworks enable the creation of agent workflows and facilitate conversations between agents with different roles, such as problem solvers and reviewers.\\n\\nAutogen Studio, a no-code interface for Autogen, simplifies the setup of communicative agent workflows. It allows for easy collaboration and problem-solving between agents, making it accessible to a wider range of users.\\n\\nUnlocking System 2 Thinking with GPT-4 Today\\n--------------------------------------------\\n\\nWhile GPT-4 may not have native system two thinking capabilities, prompt engineering and communicative agents can be used to enforce system two thinking and solve complex tasks.\\n\\nPrompt engineering, such as the chain of thought or self-consistency with chain of thought, guides the model towards thinking through problems step by step and considering multiple possibilities. However, prompt engineering may limit exploration and diversity of solutions.\\n\\nCommunicative agents, on the other hand, provide a collaborative approach to problem-solving. By simulating conversations between agents, users can leverage the strengths of system one and system two thinking. Reviewers can spot flaws in the model\\'s answers, while problem solvers can iterate and improve their solutions based on feedback.\\n\\nFrameworks like Autogen Studio make it easy to set up communicative agent workflows, allowing for seamless collaboration and problem-solving.\\n\\nThe Future of GPT-5 and System 2 Thinking\\n-----------------------------------------\\n\\nGPT-5 holds the promise of unlocking system two thinking in large language models. With enhanced reasoning abilities and reliability, GPT-5 aims to bridge the gap between system one and system two thinking, enabling models to solve complex problems more effectively.\\n\\nResearchers are actively working on developing GPT-5 with improved reasoning abilities. The focus is on enabling large language models to break down complex tasks, explore different options, and make more accurate and informed decisions.\\n\\nAs we look forward to the advancements in GPT-5, it\\'s important to continue exploring and implementing strategies like prompt engineering and communicative agents to drive system two thinking in large language models today.\\n\\n\\u200d\\n\\nFollow me on twitter: [https://twitter.com/jasonzhou1993](https://twitter.com/jasonzhou1993)\\n\\n\\u200d\\n\\nFAQs\\n----\\n\\n### 1\\\\. Can GPT-4 solve complex problems?\\n\\nGPT-4 can generate text and provide answers, but it primarily relies on system one thinking. It lacks the ability to break down complex problems into smaller steps and explore different options.\\n\\n### 2\\\\. How can prompt engineering promote system two thinking?\\n\\nPrompt engineering, such as the chain of thought or self-consistency with chain of thought, guides large language models towards thinking through problems step by step and considering multiple possibilities.\\n\\n### 3\\\\. What are communicative agents?\\n\\nCommunicative agents are multi-agent setups where users can define different agents and simulate conversations between them. This allows for collaborative problem-solving and promotes system two thinking.\\n\\n### 4\\\\. How can communicative agents be set up?\\n\\nFrameworks like Autogen Studio provide a no-code interface for setting up communicative agent workflows. Users can define agents, assign roles, and simulate conversations to solve complex problems.\\n\\n### 5\\\\. What is the future of GPT-5?\\n\\nGPT-5 aims to enhance reasoning abilities and bridge the gap between system one and system two thinking. It holds the promise of enabling large language models to solve complex problems more effectively.\\n\\nRelated articles\\n----------------\\n\\n[Browse all articles](/)\\n\\n[AI Agent\\\\\\n\\\\\\n### How to reduce 78%+ of LLM Cost\\\\\\n\\\\\\n![How to reduce 78%+ of LLM Cost](https://assets-global.website-files.com/647a9c825f099afe643b5c78/65bedbda9969f366afdfad25_tiktok%20(1).jpg)](/learning-ai/how-to-reduce-llm-cost)\\n\\n[AI Agent\\\\\\n\\\\\\n### Research agent 3.0 - Build a group of AI researchers - Step by Step Tutorial\\\\\\n\\\\\\n![Research agent 3.0 - Build a group of AI researchers - Step by Step Tutorial](https://assets-global.website-files.com/647a9c825f099afe643b5c78/65bedeabdecca18351fc45d0_tiktok%20(3).jpg)](/learning-ai/how-to-build-ai-agent-tutorial-3)\\n\\n[AI Agent\\\\\\n\\\\\\n### How to Build Agent workforce Tutorial- AI agent manages community 24/7\\\\\\n\\\\\\n![How to Build Agent workforce Tutorial- AI agent manages community 24/7](https://assets-global.website-files.com/647a9c825f099afe643b5c78/65bee17260bcfa83d917651f_tiktok%20(6).jpg)](/learning-ai/ai-agent-tutorial-2)\\n\\n### Need help building your AI apps?\\n\\nI can help you on building AI apps or give trainings\\n\\n[Tell me about your AI app ideas](mailto:jason.zhou.design@gmail.com)\\n\\n[\\ue82e](https://www.youtube.com/@AIJason-oc8wb)\\n[\\ue829](https://twitter.com/jasonzhou1993)\\n[\\ue819](https://www.linkedin.com/in/jasonzhoudesign/)\\n\\nAI Jason\\n\\n100K subscribers\\n\\n[GPT5 unlocks LLM System 2 Thinking?](https://www.youtube.com/watch?v=sD0X-lWPdxg)\\n\\nAI Jason\\n\\nSearch\\n\\nInfo\\n\\nShopping\\n\\nTap to unmute\\n\\nIf playback doesn\\'t begin shortly, try restarting your device.\\n\\nShare\\n\\nInclude playlist\\n\\nAn error occurred while retrieving sharing information. Please try again later.\\n\\nWatch later\\n\\nShare\\n\\nCopy link\\n\\nWatch on\\n\\n0:00\\n\\n/ â€¢Live\\n\\nâ€¢\\n\\n[](https://www.youtube.com/watch?v=sD0X-lWPdxg \"Watch on YouTube\")', metadata={'title': 'GPT5 unlocks LLM System 2 Thinking?', 'description': 'AI Agent,', 'ogTitle': 'GPT5 unlocks LLM System 2 Thinking?', 'ogDescription': 'AI Agent,', 'ogImage': 'https://assets-global.website-files.com/647a9c825f099afe643b5c78/65bedd7f060ee7802639f834_tiktok%20(2).jpg', 'ogLocaleAlternate': [], 'sourceURL': 'https://www.ai-jason.com/learning-ai/gpt5-llm'}),\n",
       " Document(page_content='[AI JASON](/)\\n\\nCategories\\n\\n\\ue80f\\n\\n[AI Agent](/ai/ai-agent)\\n\\n[AI Automation Tutorials](/ai/ai-automation-tutorials)\\n\\n[Langchain Tutorials](/ai/langchain-tutorial)\\n\\n[Auto GPT Tutorials](/ai/auto-gpt-tutorial)\\n\\n[Contact](/contact)\\n\\n[\\ue82e](https://www.youtube.com/@AIJason-oc8wb)\\n[\\ue829](https://twitter.com/jasonzhou1993)\\n[\\ue819](https://www.linkedin.com/in/jasonzhoudesign/)\\n\\n[AI Agent](/ai/ai-agent)\\n\\nHow to Build Agent workforce Tutorial- AI agent manages community 24/7\\n======================================================================\\n\\nAI agent manages community 24/7 - Build Agent workforce\\n=======================================================\\n\\nAre you overwhelmed with the amount of emails, messages, and tasks you need to handle every day? Do you wish you had a personal assistant to help you manage your workload? Well, thanks to advancements in artificial intelligence (AI), you can now build your own AI employees to take care of these tasks for you. In this series of videos, I will show you how to create AI agents that can act as your digital workforce, handling various roles and tasks.\\n\\nWhy Build AI Employees?\\n-----------------------\\n\\nAs a content creator with a growing YouTube channel, I found myself struggling to keep up with the influx of emails, messages from various platforms, and the need to stay on top of new purchases and video editing work. I considered outsourcing some of the work or hiring someone to help me, but then I had an idea. Instead of relying on others, why not build AI employees to handle these tasks? This would not only be an interesting experiment but also a way to push the boundaries of AI technology.\\n\\nBuilding AI employees is similar to building self-driving cars. While many researchers are focused on developing fully autonomous AI agents (level 5), there are plenty of opportunities to create AI agents that require some human guidance (level 3 or level 2). These AI agents can still deliver excellent results and are more feasible to build at this stage. My goal is not to create fully autonomous agents but to build AI employees that can get the work done with some guidance.\\n\\nSo, the first AI employee I want to build is a community moderator for my Discord community. As a content creator based in Australia, I have community members from different parts of the world with wildly different time zones. It\\'s challenging for me to respond to messages in a timely manner. Ideally, I would love to have a community moderator who can proactively engage with people 24/7. This AI moderator should have deep domain knowledge in AI and software development, stay updated on AI trends, and engage with the community proactively.\\n\\nChallenges to Overcome\\n----------------------\\n\\nBuilding an AI community moderator comes with its own set of challenges. Firstly, how should the AI behave in a group chat setup? Most AI agents are designed for one-on-one conversations, but in a Discord community, there can be multiple people talking at the same time. Secondly, the AI moderator should have a long-term memory of each community member to make conversations feel more genuine and to connect community members with similar interests. Lastly, the AI moderator should be able to retrieve knowledge from various sources, such as my YouTube channel, GitHub repository, and the internet, to provide up-to-date information.\\n\\nTo overcome these challenges, I found an open-source project called Discord AI chatbot on GitHub. This project integrates OpenAI into a Discord bot, taking care of the network setup and providing design patterns for AI behavior in a group chat setup. It allows me to define trigger words that activate the AI moderator and retrieve the relevant conversation history. While this project has some limitations, such as limited conversation history and the inability to perform complex tasks, it provides a flexible foundation for customization.\\n\\n![](https://assets-global.website-files.com/647a9c825f099afe643b5c78/65bee0a5f2e303fd2cefe0b3_Copy%20of%20Your%20paragraph%20text.jpg)\\n\\nGetting Started: Installing Discord AI Chatbot\\n----------------------------------------------\\n\\nTo get started, you need to install the Discord AI chatbot. Once the AI chatbot is up and running, you can customize its behavior by modifying the config.yaml file. You can change the name of the bot, define trigger words, and add predefined personalities to give the bot a specific character.\\n\\nEnhancing the AI Moderator: Building an AI Agent\\n------------------------------------------------\\n\\nWhile the AI chatbot provides a good starting point, I wanted to create an AI moderator with more advanced capabilities. I wanted the AI moderator to have a long-term memory, retrieve knowledge from various sources, and schedule tasks. To achieve this, I used the Launching Agent framework and integrated it into the AI chatbot.\\n\\nFirstly, I created a knowledge retrieval function to extract information from my YouTube channel, GitHub repository, and the internet. I used a platform called Random CI to turn my website into a knowledge base and used the Launching Agent\\'s large language model to perform knowledge retrieval. I also implemented functions for online research, such as Google search and website scripting, to gather information from the internet.\\n\\nNext, I created a research agent that combines the knowledge retrieval function and online research tools. This research agent can search my internal knowledge base first and then perform online research if necessary. It can provide relevant information and links to answer questions from the community.\\n\\nTo integrate the research agent into the AI chatbot, I modified the AI utility file. I updated the message handling function to pass the user\\'s message to the research agent and added a mapping of agents for each user. This allows each user to have a unique chat history and memory. I also added a scheduler feature to trigger the research agent to generate GitHub reports every two days.\\n\\nGenerating GitHub Reports: Sharing AI Trends and News\\n-----------------------------------------------------\\n\\nIn addition to moderating the community, I wanted the AI agent to share the latest AI trends and news from various sources, such as Twitter, GitHub, and newsletters. For the initial MVP, I decided to generate GitHub reports every two days. The AI agent would check the GitHub trending page, filter out projects related to generative AI, and write a report to keep the community updated.\\n\\nTo achieve this, I used a platform called BrowseAI to extract structured data from the GitHub trending page. BrowseAI allows me to define the elements I want to extract, such as the name of the repo, the link, and the number of stars. I integrated BrowseAI into the AI agent to script the GitHub trending page and retrieve the relevant information.\\n\\nI also implemented a scheduler feature in the AI chatbot to trigger the generation of GitHub reports every two days. This feature allows the AI agent to automatically post the reports in the Discord channels that have enabled the schedule task.\\n\\nDeployment and Continuous Operation\\n-----------------------------------\\n\\nTo ensure the AI moderator operates 24/7, you can deploy the AI chatbot on a cloud service. One option is to use Render, a platform that allows you to deploy web services. Simply upload your project to GitHub, create a new web service on Render, and configure the necessary environment variables. Render will handle the deployment and ensure your AI moderator stays active.\\n\\nHowever, keep in mind that free versions of cloud services may have limitations, such as inactivity timeouts. To prevent the AI moderator from going inactive, you can use uptime monitoring services like Uptime Robot to ping your API endpoint at regular intervals.\\n\\nWith your AI moderator deployed and continuously operational, you can enjoy the benefits of having a 24/7 community manager. The AI moderator will handle messages, answer questions, and share the latest AI trends and news, allowing you to focus on other aspects of your content creation.\\n\\nConclusion\\n----------\\n\\nBuilding AI employees, such as a community moderator, can greatly enhance your productivity and efficiency. With the right tools and frameworks, you can create AI agents that handle various tasks and roles, providing a seamless experience for your community members. By combining knowledge retrieval, online research, and scheduling capabilities, you can build an AI moderator that stays engaged with your community 24/7.\\n\\nðŸ”— Links\\n\\n*   Github repo: [https://github.com/JayZeeDesign/Discord-AI-Chatbot](https://github.com/JayZeeDesign/Discord-AI-Chatbot)\\n    \\n*   Follow me on twitter: [https://twitter.com/jasonzhou1993](https://twitter.com/jasonzhou1993)\\n    \\n\\n\\u200d\\n\\nFrequently Asked Questions\\n--------------------------\\n\\n### 1\\\\. Can I customize the behavior of the AI moderator?\\n\\nYes, you can customize the behavior of the AI moderator by modifying the config.yaml file. You can change the name of the bot, define trigger words, and add predefined personalities to give the bot a specific character.\\n\\n### 2\\\\. Can the AI moderator handle multiple conversations in a group chat setup?\\n\\nYes, the AI moderator is designed to handle group chat setups. It can understand the context of the conversation and respond accordingly, even when multiple people are talking at the same time.\\n\\n### 3\\\\. How does the AI moderator retrieve knowledge from different sources?\\n\\nThe AI moderator can retrieve knowledge from various sources, such as your YouTube channel, GitHub repository, and the internet. It uses a combination of knowledge retrieval techniques and online research tools to gather relevant information.\\n\\n### 4\\\\. Can the AI moderator generate reports and share AI trends?\\n\\nYes, the AI moderator can generate reports and share the latest AI trends. It can retrieve information from GitHub, filter out projects related to generative AI, and write reports to keep the community updated.\\n\\n### 5\\\\. How can I deploy the AI moderator on a cloud service?\\n\\nTo deploy the AI moderator on a cloud service, you can use platforms like Render. Simply upload your project to GitHub, create a new web service on Render, and configure the necessary environment variables. Render will handle the deployment and ensure your AI moderator stays active.\\n\\nRelated articles\\n----------------\\n\\n[Browse all articles](/)\\n\\n[AI Agent\\\\\\n\\\\\\n### How to reduce 78%+ of LLM Cost\\\\\\n\\\\\\n![How to reduce 78%+ of LLM Cost](https://assets-global.website-files.com/647a9c825f099afe643b5c78/65bedbda9969f366afdfad25_tiktok%20(1).jpg)](/learning-ai/how-to-reduce-llm-cost)\\n\\n[AI Agent\\\\\\n\\\\\\n### GPT5 unlocks LLM System 2 Thinking?\\\\\\n\\\\\\n![GPT5 unlocks LLM System 2 Thinking?\\\\\\n](https://assets-global.website-files.com/647a9c825f099afe643b5c78/65bedd7f060ee7802639f834_tiktok%20(2).jpg)](/learning-ai/gpt5-llm)\\n\\n[AI Agent\\\\\\n\\\\\\n### Research agent 3.0 - Build a group of AI researchers - Step by Step Tutorial\\\\\\n\\\\\\n![Research agent 3.0 - Build a group of AI researchers - Step by Step Tutorial](https://assets-global.website-files.com/647a9c825f099afe643b5c78/65bedeabdecca18351fc45d0_tiktok%20(3).jpg)](/learning-ai/how-to-build-ai-agent-tutorial-3)\\n\\n### Need help building your AI apps?\\n\\nI can help you on building AI apps or give trainings\\n\\n[Tell me about your AI app ideas](mailto:jason.zhou.design@gmail.com)\\n\\n[\\ue82e](https://www.youtube.com/@AIJason-oc8wb)\\n[\\ue829](https://twitter.com/jasonzhou1993)\\n[\\ue819](https://www.linkedin.com/in/jasonzhoudesign/)\\n\\nAI Jason\\n\\n100K subscribers\\n\\n[AI agent manages community 24/7 - Build Agent workforce ep#1](https://www.youtube.com/watch?v=yhBiVrigWNI)\\n\\nAI Jason\\n\\nSearch\\n\\nInfo\\n\\nShopping\\n\\nTap to unmute\\n\\nIf playback doesn\\'t begin shortly, try restarting your device.\\n\\nShare\\n\\nInclude playlist\\n\\nAn error occurred while retrieving sharing information. Please try again later.\\n\\nWatch later\\n\\nShare\\n\\nCopy link\\n\\nWatch on\\n\\n0:00\\n\\n/ â€¢Live\\n\\nâ€¢\\n\\n[](https://www.youtube.com/watch?v=yhBiVrigWNI \"Watch on YouTube\")', metadata={'title': 'How to Build Agent workforce Tutorial- AI agent manages community 24/7', 'description': 'AI Agent,', 'ogTitle': 'How to Build Agent workforce Tutorial- AI agent manages community 24/7', 'ogDescription': 'AI Agent,', 'ogImage': 'https://assets-global.website-files.com/647a9c825f099afe643b5c78/65bee17260bcfa83d917651f_tiktok%20(6).jpg', 'ogLocaleAlternate': [], 'sourceURL': 'https://www.ai-jason.com/learning-ai/ai-agent-tutorial-2'})]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='[AI JASON](/)\\n\\nCategories\\n\\n\\ue80f\\n\\n[AI Agent](/ai/ai-agent)\\n\\n[AI Automation Tutorials](/ai/ai-automation-tutorials)\\n\\n[Langchain Tutorials](/ai/langchain-tutorial)\\n\\n[Auto GPT Tutorials](/ai/auto-gpt-tutorial)\\n\\n[Contact](/contact)\\n\\n[\\ue82e](https://www.youtube.com/@AIJason-oc8wb)\\n[\\ue829](https://twitter.com/jasonzhou1993)\\n[\\ue819](https://www.linkedin.com/in/jasonzhoudesign/)\\n\\n[AI Agent](/ai/ai-agent)\\n\\nHow to reduce 78%+ of LLM Cost\\n==============================\\n\\nHow to reduce 78%+ of LLM Cost\\n==============================\\n\\nAre you building AI agents or using chatGPT? If so, you may be facing the challenge of high costs associated with large language models (LLM). In this article, we will explore effective strategies to reduce LLM costs by up to 78%. Let\\'s dive in!\\n\\n\\u200d\\n\\n1\\\\. Change Model\\n----------------\\n\\nOne effective way to reduce LLM costs is to change the model you are using. Different models have different costs associated with them. For example, GPT-4 is the most powerful but also the most expensive model, while Mistro 7B is significantly cheaper. By using a smaller model for specific tasks and reserving the more expensive model for complex questions, you can achieve significant cost savings.\\n\\n![](https://assets-global.website-files.com/647a9c825f099afe643b5c78/65bedacac82767caefbdf0a0_1.jpg)\\n\\n2\\\\. Large Language Model Router\\n-------------------------------\\n\\nThe concept of a large language model router involves using a cascade of models to handle different types of questions. Cheaper models are used first, and if they are unable to provide a satisfactory answer, the question is passed on to a more expensive model. This approach leverages the significant cost difference between models and can result in substantial cost savings.\\n\\n![](https://assets-global.website-files.com/647a9c825f099afe643b5c78/65bedae566010ad14fe382cd_llm%20router.jpg)\\n\\n3\\\\. Multi-Agent Setup\\n---------------------\\n\\nAnother strategy is to set up multiple agents, each using a different model. The first agent attempts to complete the task using a cheaper model, and if it fails, the next agent is invoked. By using this multi-agent setup, you can achieve similar or even better success rates while significantly reducing costs.\\n\\n![](https://assets-global.website-files.com/647a9c825f099afe643b5c78/65bedaefa7461fca4f82df51_autogen.jpg)\\n\\n4\\\\. LLM Lingua\\n--------------\\n\\nLLM Lingua is a method introduced by Microsoft that focuses on optimizing the input and output of large language models. By removing unnecessary tokens and words from the input, you can significantly reduce the cost of running the model. This method is particularly effective for tasks such as summarization or answering specific questions based on a transcript.\\n\\n![](https://assets-global.website-files.com/647a9c825f099afe643b5c78/65bedaf791724343e65da125_llm%20lingua.jpg)\\n\\n5\\\\. Optimize Agent Memory\\n-------------------------\\n\\nOptimizing agent memory is another way to reduce LLM costs. By carefully managing the amount of conversation history stored in memory, you can minimize the number of tokens required for each interaction. This can lead to significant cost savings, especially when dealing with long conversations.\\n\\n![](https://assets-global.website-files.com/647a9c825f099afe643b5c78/65bedb03355b5d49f9ac7f8e_memory%20opt.jpg)\\n\\n6\\\\. Observability\\n-----------------\\n\\nHaving a deep understanding of the cost patterns in your LLM application is crucial for effective cost optimization. By using observability platforms like L Smith, you can monitor and log the cost for each large language model. This allows you to identify areas where costs can be optimized and make informed decisions to reduce overall expenses.\\n\\nBy implementing these strategies, you can reduce LLM costs by up to 78% or more. Remember, reducing costs while maintaining performance and user experience is a critical skill for AI startups. Stay proactive and continuously optimize your LLM usage to maximize efficiency and profitability.\\n\\n\\u200d\\n\\nGet free HubSpot AI For Marketers Course: [https://clickhubspot.com/xut](https://clickhubspot.com/xut)\\n\\nðŸ”— Links\\n\\n*   Follow me on twitter: [https://twitter.com/jasonzhou1993](https://twitter.com/jasonzhou1993)\\n    \\n*   Join my AI email list: [https://crafters.ai/](https://crafters.ai/)\\n    \\n*   My discord: [https://discord.gg/eZXprSaCDE](https://discord.gg/eZXprSaCDE)\\n    \\n*   Inbox Agent: [https://www.youtube.com/watch?v=Jv\\\\_e6Rt4vWE&t=23s&ab\\\\_channel=AIJason](https://www.youtube.com/watch?v=Jv_e6Rt4vWE&t=23s&ab_channel=AIJason)\\n    \\n*   Research Agent: [https://www.youtube.com/watch?v=ogQUlS7CkYA&t=299s&ab\\\\_channel=AIJason](https://www.youtube.com/watch?v=ogQUlS7CkYA&t=299s&ab_channel=AIJason)\\n    \\n*   James Brigg on Agent Memory: [https://www.pinecone.io/learn/series/langchain/langchain-conversational-memory/](https://www.pinecone.io/learn/series/langchain/langchain-conversational-memory/)\\n    \\n*   Another video about details for LLM cost tracking: [https://www.youtube.com/watch?v=Alb2kjUzpZ8&ab\\\\_channel=LearnfromOpenSourcewithElie](https://www.youtube.com/watch?v=Alb2kjUzpZ8&ab_channel=LearnfromOpenSourcewithElie)\\n    \\n\\n\\u200d\\n\\nFrequently Asked Questions\\n--------------------------\\n\\n### Q: How can I determine which model is the most cost-effective for my AI application?\\n\\nA: To determine the most cost-effective model for your AI application, you should consider the specific tasks and requirements of your application. Evaluate the performance and cost trade-offs of different models and choose the one that best fits your needs.\\n\\n### Q: Are there any open-source solutions available for large language model routing?\\n\\nA: While there are no specific open-source solutions for large language model routing, you can explore frameworks like Hugging Face\\'s Hugging GPT, which allows you to build your own routing logic using a large language model as a controller.\\n\\n### Q: How often should I monitor and optimize my LLM costs?\\n\\nA: It is recommended to monitor and optimize your LLM costs regularly, especially as your usage and user base grow. Keep track of cost patterns, identify areas for improvement, and implement cost optimization strategies accordingly.\\n\\n### Q: Can I reduce LLM costs without compromising performance?\\n\\nA: Yes, it is possible to reduce LLM costs without compromising performance. By carefully selecting the right models for specific tasks, optimizing agent memory, and using techniques like LLM Lingua, you can achieve cost savings while maintaining high performance and user experience.\\n\\n### Q: Are there any other cost optimization methods for LLM that I should be aware of?\\n\\nA: While the methods mentioned in this article are effective for reducing LLM costs, there may be other innovative approaches and techniques available. Stay updated with the latest research and developments in the field to discover new cost optimization methods.\\n\\nRelated articles\\n----------------\\n\\n[Browse all articles](/)\\n\\n[AI Agent\\\\\\n\\\\\\n### GPT5 unlocks LLM System 2 Thinking?\\\\\\n\\\\\\n![GPT5 unlocks LLM System 2 Thinking?\\\\\\n](https://assets-global.website-files.com/647a9c825f099afe643b5c78/65bedd7f060ee7802639f834_tiktok%20(2).jpg)](/learning-ai/gpt5-llm)\\n\\n[AI Agent\\\\\\n\\\\\\n### Research agent 3.0 - Build a group of AI researchers - Step by Step Tutorial\\\\\\n\\\\\\n![Research agent 3.0 - Build a group of AI researchers - Step by Step Tutorial](https://assets-global.website-files.com/647a9c825f099afe643b5c78/65bedeabdecca18351fc45d0_tiktok%20(3).jpg)](/learning-ai/how-to-build-ai-agent-tutorial-3)\\n\\n[AI Agent\\\\\\n\\\\\\n### How to Build Agent workforce Tutorial- AI agent manages community 24/7\\\\\\n\\\\\\n![How to Build Agent workforce Tutorial- AI agent manages community 24/7](https://assets-global.website-files.com/647a9c825f099afe643b5c78/65bee17260bcfa83d917651f_tiktok%20(6).jpg)](/learning-ai/ai-agent-tutorial-2)\\n\\n### Need help building your AI apps?\\n\\nI can help you on building AI apps or give trainings\\n\\n[Tell me about your AI app ideas](mailto:jason.zhou.design@gmail.com)\\n\\n[\\ue82e](https://www.youtube.com/@AIJason-oc8wb)\\n[\\ue829](https://twitter.com/jasonzhou1993)\\n[\\ue819](https://www.linkedin.com/in/jasonzhoudesign/)\\n\\nAI Jason\\n\\n100K subscribers\\n\\n[The REAL cost of LLM (And How to reduce 78%+ of Cost)](https://www.youtube.com/watch?v=lHxl5SchjPA)\\n\\nAI Jason\\n\\nSearch\\n\\nInfo\\n\\nShopping\\n\\nTap to unmute\\n\\nIf playback doesn\\'t begin shortly, try restarting your device.\\n\\nShare\\n\\nInclude playlist\\n\\nAn error occurred while retrieving sharing information. Please try again later.\\n\\nWatch later\\n\\nShare\\n\\nCopy link\\n\\nWatch on\\n\\n0:00\\n\\n/ â€¢Live\\n\\nâ€¢\\n\\n[](https://www.youtube.com/watch?v=lHxl5SchjPA \"Watch on YouTube\")', metadata={'title': 'How to reduce 78%+ of LLM Cost', 'description': 'AI Agent, Real cost of LLM', 'ogTitle': 'How to reduce 78%+ of LLM Cost', 'ogDescription': 'AI Agent, Real cost of LLM', 'ogImage': 'https://assets-global.website-files.com/647a9c825f099afe643b5c78/65bedbda9969f366afdfad25_tiktok%20(1).jpg', 'ogLocaleAlternate': [], 'sourceURL': 'https://www.ai-jason.com/learning-ai/how-to-reduce-llm-cost'}),\n",
       " Document(page_content='[AI JASON](/)\\n\\nCategories\\n\\n\\ue80f\\n\\n[AI Agent](/ai/ai-agent)\\n\\n[AI Automation Tutorials](/ai/ai-automation-tutorials)\\n\\n[Langchain Tutorials](/ai/langchain-tutorial)\\n\\n[Auto GPT Tutorials](/ai/auto-gpt-tutorial)\\n\\n[Contact](/contact)\\n\\n[\\ue82e](https://www.youtube.com/@AIJason-oc8wb)\\n[\\ue829](https://twitter.com/jasonzhou1993)\\n[\\ue819](https://www.linkedin.com/in/jasonzhoudesign/)\\n\\n[AI Agent](/ai/ai-agent)\\n\\nGPT5 unlocks LLM System 2 Thinking?\\n===================================\\n\\nGPT5 unlocks LLM System 2 Thinking?\\n===================================\\n\\nAI has come a long way in recent years, with large language models (LLMs) like GPT-4 impressing us with their ability to generate text. However, these models primarily rely on system one thinking, which is fast and intuitive but lacks the ability to break down complex problems into smaller steps and explore different options. This limitation has led researchers to focus on developing GPT-5 with enhanced reasoning abilities and reliability.\\n\\nThe Two Modes of Thinking\\n-------------------------\\n\\nIn his book \"Thinking, Fast and Slow,\" Daniel Kahneman introduces the concept of two modes of thinking: system one and system two. System one thinking is our fast, intuitive brain that quickly provides answers based on memorized information. On the other hand, system two thinking is slower but more rational, requiring us to take time, calculate, and analyze before arriving at an answer.\\n\\nSimilarly, large language models like GPT-4 primarily rely on system one thinking. They predict the best next words based on the sequence of words they have seen before, without truly understanding the complex problems they are trying to solve.\\n\\n![](https://assets-global.website-files.com/img/image-placeholder.svg)\\n\\n\\u200d\\n\\nThe Limitations of GPT-4\\n------------------------\\n\\nGPT-4, despite its impressive capabilities, lacks system two thinking. It cannot break down complex tasks into smaller steps or explore different options. It simply generates text based on patterns it has learned from training data. This limitation becomes evident when GPT-4 is faced with complex problems that require deeper analysis and reasoning.\\n\\nFor example, in a video by Veritasium, college students were asked seemingly simple questions like the time it takes for the Earth to go around the Sun. Many of them answered incorrectly because they relied on system one thinking, providing automatic intuitive answers without truly considering the question.\\n\\nLarge language models like GPT-4 face a similar challenge. They lack the ability to think critically and break down complex problems into smaller, manageable steps. This is where GPT-5 comes in.\\n\\nThe Promise of GPT-5\\n--------------------\\n\\nGPT-5 aims to enhance the reasoning abilities of large language models and introduce system two thinking. OpenAI\\'s Sam Altman mentioned in an interview with Bill Gates that the key milestones for GPT-5 will be around reasoning ability and reliability.\\n\\nCurrently, GPT-4 can reason in extremely limited ways and lacks reliability. It may provide correct answers, but it doesn\\'t always know which answer is the best. GPT-5 aims to improve this by increasing reliability and enhancing reasoning abilities.\\n\\nAltman also mentioned the possibility of GPT-5 being able to solve complex math equations by applying transformations an arbitrary number of times. This would require a more complex control logic for reasoning, going beyond what is currently possible with GPT-4.\\n\\nHowever, simply improving the model itself is not enough. There are ways to enforce system two thinking in large language models today, even with GPT-4.\\n\\nPromoting System 2 Thinking in Large Language Models\\n----------------------------------------------------\\n\\nThere are two common strategies to promote system two thinking in large language models: prompt engineering and communicative agents.\\n\\n### Prompt Engineering\\n\\nPrompt engineering is a simple and common method to guide large language models towards system two thinking. One approach is the \"chain of thought,\" where a sentence is inserted step by step before the model generates any text. This forces the model to break down the problem into smaller steps and think through each one.\\n\\nAnother approach is to provide a few short prompt examples instead of a step-by-step process. These examples guide the model towards thinking through different steps and considering multiple possibilities.\\n\\nWhile prompt engineering can be effective in promoting system two thinking, it has limitations. It often restricts the model to consider only one possibility and may not explore diverse options, similar to how humans approach creative problem-solving.\\n\\nTo address this limitation, more advanced prompting tactics like self-consistency with chain of thought (SCCOT) have been proposed. SCCOT involves running the chain of thought process multiple times and reviewing and voting on the most reasonable answers. This allows for some exploration of different options but requires more implementation effort.\\n\\nAnother advanced prompting tactic is the tree of sorts, which simulates a tree search to explore different options and paths. It keeps track of all the paths explored and allows for backtracking if the current path doesn\\'t lead to the desired outcome. However, implementing the tree of sorts is complex and requires significant implementation effort.\\n\\n### Communicative Agents\\n\\nCommunicative agents provide an elegant solution to promote system two thinking in large language models. These are multi-agent setups where users can define different agents and simulate conversations between them. The agents can reflect and spot flaws in each other\\'s perspectives and thinking processes.\\n\\nCommunicative agents have shown promise in enhancing system two thinking. They allow for dedicated agents to review and critique the model\\'s answers, identifying flaws and providing feedback. This collaborative approach mimics how humans solve complex problems by exploring multiple options and learning from each other.\\n\\nSetting up communicative agents can be done using various frameworks like ChatGPT, MetaGPT, Autogen, and Crew AI. These frameworks enable the creation of agent workflows and facilitate conversations between agents with different roles, such as problem solvers and reviewers.\\n\\nAutogen Studio, a no-code interface for Autogen, simplifies the setup of communicative agent workflows. It allows for easy collaboration and problem-solving between agents, making it accessible to a wider range of users.\\n\\nUnlocking System 2 Thinking with GPT-4 Today\\n--------------------------------------------\\n\\nWhile GPT-4 may not have native system two thinking capabilities, prompt engineering and communicative agents can be used to enforce system two thinking and solve complex tasks.\\n\\nPrompt engineering, such as the chain of thought or self-consistency with chain of thought, guides the model towards thinking through problems step by step and considering multiple possibilities. However, prompt engineering may limit exploration and diversity of solutions.\\n\\nCommunicative agents, on the other hand, provide a collaborative approach to problem-solving. By simulating conversations between agents, users can leverage the strengths of system one and system two thinking. Reviewers can spot flaws in the model\\'s answers, while problem solvers can iterate and improve their solutions based on feedback.\\n\\nFrameworks like Autogen Studio make it easy to set up communicative agent workflows, allowing for seamless collaboration and problem-solving.\\n\\nThe Future of GPT-5 and System 2 Thinking\\n-----------------------------------------\\n\\nGPT-5 holds the promise of unlocking system two thinking in large language models. With enhanced reasoning abilities and reliability, GPT-5 aims to bridge the gap between system one and system two thinking, enabling models to solve complex problems more effectively.\\n\\nResearchers are actively working on developing GPT-5 with improved reasoning abilities. The focus is on enabling large language models to break down complex tasks, explore different options, and make more accurate and informed decisions.\\n\\nAs we look forward to the advancements in GPT-5, it\\'s important to continue exploring and implementing strategies like prompt engineering and communicative agents to drive system two thinking in large language models today.\\n\\n\\u200d\\n\\nFollow me on twitter: [https://twitter.com/jasonzhou1993](https://twitter.com/jasonzhou1993)\\n\\n\\u200d\\n\\nFAQs\\n----\\n\\n### 1\\\\. Can GPT-4 solve complex problems?\\n\\nGPT-4 can generate text and provide answers, but it primarily relies on system one thinking. It lacks the ability to break down complex problems into smaller steps and explore different options.\\n\\n### 2\\\\. How can prompt engineering promote system two thinking?\\n\\nPrompt engineering, such as the chain of thought or self-consistency with chain of thought, guides large language models towards thinking through problems step by step and considering multiple possibilities.\\n\\n### 3\\\\. What are communicative agents?\\n\\nCommunicative agents are multi-agent setups where users can define different agents and simulate conversations between them. This allows for collaborative problem-solving and promotes system two thinking.\\n\\n### 4\\\\. How can communicative agents be set up?\\n\\nFrameworks like Autogen Studio provide a no-code interface for setting up communicative agent workflows. Users can define agents, assign roles, and simulate conversations to solve complex problems.\\n\\n### 5\\\\. What is the future of GPT-5?\\n\\nGPT-5 aims to enhance reasoning abilities and bridge the gap between system one and system two thinking. It holds the promise of enabling large language models to solve complex problems more effectively.\\n\\nRelated articles\\n----------------\\n\\n[Browse all articles](/)\\n\\n[AI Agent\\\\\\n\\\\\\n### How to reduce 78%+ of LLM Cost\\\\\\n\\\\\\n![How to reduce 78%+ of LLM Cost](https://assets-global.website-files.com/647a9c825f099afe643b5c78/65bedbda9969f366afdfad25_tiktok%20(1).jpg)](/learning-ai/how-to-reduce-llm-cost)\\n\\n[AI Agent\\\\\\n\\\\\\n### Research agent 3.0 - Build a group of AI researchers - Step by Step Tutorial\\\\\\n\\\\\\n![Research agent 3.0 - Build a group of AI researchers - Step by Step Tutorial](https://assets-global.website-files.com/647a9c825f099afe643b5c78/65bedeabdecca18351fc45d0_tiktok%20(3).jpg)](/learning-ai/how-to-build-ai-agent-tutorial-3)\\n\\n[AI Agent\\\\\\n\\\\\\n### How to Build Agent workforce Tutorial- AI agent manages community 24/7\\\\\\n\\\\\\n![How to Build Agent workforce Tutorial- AI agent manages community 24/7](https://assets-global.website-files.com/647a9c825f099afe643b5c78/65bee17260bcfa83d917651f_tiktok%20(6).jpg)](/learning-ai/ai-agent-tutorial-2)\\n\\n### Need help building your AI apps?\\n\\nI can help you on building AI apps or give trainings\\n\\n[Tell me about your AI app ideas](mailto:jason.zhou.design@gmail.com)\\n\\n[\\ue82e](https://www.youtube.com/@AIJason-oc8wb)\\n[\\ue829](https://twitter.com/jasonzhou1993)\\n[\\ue819](https://www.linkedin.com/in/jasonzhoudesign/)\\n\\nAI Jason\\n\\n100K subscribers\\n\\n[GPT5 unlocks LLM System 2 Thinking?](https://www.youtube.com/watch?v=sD0X-lWPdxg)\\n\\nAI Jason\\n\\nSearch\\n\\nInfo\\n\\nShopping\\n\\nTap to unmute\\n\\nIf playback doesn\\'t begin shortly, try restarting your device.\\n\\nShare\\n\\nInclude playlist\\n\\nAn error occurred while retrieving sharing information. Please try again later.\\n\\nWatch later\\n\\nShare\\n\\nCopy link\\n\\nWatch on\\n\\n0:00\\n\\n/ â€¢Live\\n\\nâ€¢\\n\\n[](https://www.youtube.com/watch?v=sD0X-lWPdxg \"Watch on YouTube\")', metadata={'title': 'GPT5 unlocks LLM System 2 Thinking?', 'description': 'AI Agent,', 'ogTitle': 'GPT5 unlocks LLM System 2 Thinking?', 'ogDescription': 'AI Agent,', 'ogImage': 'https://assets-global.website-files.com/647a9c825f099afe643b5c78/65bedd7f060ee7802639f834_tiktok%20(2).jpg', 'ogLocaleAlternate': [], 'sourceURL': 'https://www.ai-jason.com/learning-ai/gpt5-llm'}),\n",
       " Document(page_content='[AI JASON](/)\\n\\nCategories\\n\\n\\ue80f\\n\\n[AI Agent](/ai/ai-agent)\\n\\n[AI Automation Tutorials](/ai/ai-automation-tutorials)\\n\\n[Langchain Tutorials](/ai/langchain-tutorial)\\n\\n[Auto GPT Tutorials](/ai/auto-gpt-tutorial)\\n\\n[Contact](/contact)\\n\\n[\\ue82e](https://www.youtube.com/@AIJason-oc8wb)\\n[\\ue829](https://twitter.com/jasonzhou1993)\\n[\\ue819](https://www.linkedin.com/in/jasonzhoudesign/)\\n\\n[AI Agent](/ai/ai-agent)\\n\\nHow to Build Agent workforce Tutorial- AI agent manages community 24/7\\n======================================================================\\n\\nAI agent manages community 24/7 - Build Agent workforce\\n=======================================================\\n\\nAre you overwhelmed with the amount of emails, messages, and tasks you need to handle every day? Do you wish you had a personal assistant to help you manage your workload? Well, thanks to advancements in artificial intelligence (AI), you can now build your own AI employees to take care of these tasks for you. In this series of videos, I will show you how to create AI agents that can act as your digital workforce, handling various roles and tasks.\\n\\nWhy Build AI Employees?\\n-----------------------\\n\\nAs a content creator with a growing YouTube channel, I found myself struggling to keep up with the influx of emails, messages from various platforms, and the need to stay on top of new purchases and video editing work. I considered outsourcing some of the work or hiring someone to help me, but then I had an idea. Instead of relying on others, why not build AI employees to handle these tasks? This would not only be an interesting experiment but also a way to push the boundaries of AI technology.\\n\\nBuilding AI employees is similar to building self-driving cars. While many researchers are focused on developing fully autonomous AI agents (level 5), there are plenty of opportunities to create AI agents that require some human guidance (level 3 or level 2). These AI agents can still deliver excellent results and are more feasible to build at this stage. My goal is not to create fully autonomous agents but to build AI employees that can get the work done with some guidance.\\n\\nSo, the first AI employee I want to build is a community moderator for my Discord community. As a content creator based in Australia, I have community members from different parts of the world with wildly different time zones. It\\'s challenging for me to respond to messages in a timely manner. Ideally, I would love to have a community moderator who can proactively engage with people 24/7. This AI moderator should have deep domain knowledge in AI and software development, stay updated on AI trends, and engage with the community proactively.\\n\\nChallenges to Overcome\\n----------------------\\n\\nBuilding an AI community moderator comes with its own set of challenges. Firstly, how should the AI behave in a group chat setup? Most AI agents are designed for one-on-one conversations, but in a Discord community, there can be multiple people talking at the same time. Secondly, the AI moderator should have a long-term memory of each community member to make conversations feel more genuine and to connect community members with similar interests. Lastly, the AI moderator should be able to retrieve knowledge from various sources, such as my YouTube channel, GitHub repository, and the internet, to provide up-to-date information.\\n\\nTo overcome these challenges, I found an open-source project called Discord AI chatbot on GitHub. This project integrates OpenAI into a Discord bot, taking care of the network setup and providing design patterns for AI behavior in a group chat setup. It allows me to define trigger words that activate the AI moderator and retrieve the relevant conversation history. While this project has some limitations, such as limited conversation history and the inability to perform complex tasks, it provides a flexible foundation for customization.\\n\\n![](https://assets-global.website-files.com/647a9c825f099afe643b5c78/65bee0a5f2e303fd2cefe0b3_Copy%20of%20Your%20paragraph%20text.jpg)\\n\\nGetting Started: Installing Discord AI Chatbot\\n----------------------------------------------\\n\\nTo get started, you need to install the Discord AI chatbot. Once the AI chatbot is up and running, you can customize its behavior by modifying the config.yaml file. You can change the name of the bot, define trigger words, and add predefined personalities to give the bot a specific character.\\n\\nEnhancing the AI Moderator: Building an AI Agent\\n------------------------------------------------\\n\\nWhile the AI chatbot provides a good starting point, I wanted to create an AI moderator with more advanced capabilities. I wanted the AI moderator to have a long-term memory, retrieve knowledge from various sources, and schedule tasks. To achieve this, I used the Launching Agent framework and integrated it into the AI chatbot.\\n\\nFirstly, I created a knowledge retrieval function to extract information from my YouTube channel, GitHub repository, and the internet. I used a platform called Random CI to turn my website into a knowledge base and used the Launching Agent\\'s large language model to perform knowledge retrieval. I also implemented functions for online research, such as Google search and website scripting, to gather information from the internet.\\n\\nNext, I created a research agent that combines the knowledge retrieval function and online research tools. This research agent can search my internal knowledge base first and then perform online research if necessary. It can provide relevant information and links to answer questions from the community.\\n\\nTo integrate the research agent into the AI chatbot, I modified the AI utility file. I updated the message handling function to pass the user\\'s message to the research agent and added a mapping of agents for each user. This allows each user to have a unique chat history and memory. I also added a scheduler feature to trigger the research agent to generate GitHub reports every two days.\\n\\nGenerating GitHub Reports: Sharing AI Trends and News\\n-----------------------------------------------------\\n\\nIn addition to moderating the community, I wanted the AI agent to share the latest AI trends and news from various sources, such as Twitter, GitHub, and newsletters. For the initial MVP, I decided to generate GitHub reports every two days. The AI agent would check the GitHub trending page, filter out projects related to generative AI, and write a report to keep the community updated.\\n\\nTo achieve this, I used a platform called BrowseAI to extract structured data from the GitHub trending page. BrowseAI allows me to define the elements I want to extract, such as the name of the repo, the link, and the number of stars. I integrated BrowseAI into the AI agent to script the GitHub trending page and retrieve the relevant information.\\n\\nI also implemented a scheduler feature in the AI chatbot to trigger the generation of GitHub reports every two days. This feature allows the AI agent to automatically post the reports in the Discord channels that have enabled the schedule task.\\n\\nDeployment and Continuous Operation\\n-----------------------------------\\n\\nTo ensure the AI moderator operates 24/7, you can deploy the AI chatbot on a cloud service. One option is to use Render, a platform that allows you to deploy web services. Simply upload your project to GitHub, create a new web service on Render, and configure the necessary environment variables. Render will handle the deployment and ensure your AI moderator stays active.\\n\\nHowever, keep in mind that free versions of cloud services may have limitations, such as inactivity timeouts. To prevent the AI moderator from going inactive, you can use uptime monitoring services like Uptime Robot to ping your API endpoint at regular intervals.\\n\\nWith your AI moderator deployed and continuously operational, you can enjoy the benefits of having a 24/7 community manager. The AI moderator will handle messages, answer questions, and share the latest AI trends and news, allowing you to focus on other aspects of your content creation.\\n\\nConclusion\\n----------\\n\\nBuilding AI employees, such as a community moderator, can greatly enhance your productivity and efficiency. With the right tools and frameworks, you can create AI agents that handle various tasks and roles, providing a seamless experience for your community members. By combining knowledge retrieval, online research, and scheduling capabilities, you can build an AI moderator that stays engaged with your community 24/7.\\n\\nðŸ”— Links\\n\\n*   Github repo: [https://github.com/JayZeeDesign/Discord-AI-Chatbot](https://github.com/JayZeeDesign/Discord-AI-Chatbot)\\n    \\n*   Follow me on twitter: [https://twitter.com/jasonzhou1993](https://twitter.com/jasonzhou1993)\\n    \\n\\n\\u200d\\n\\nFrequently Asked Questions\\n--------------------------\\n\\n### 1\\\\. Can I customize the behavior of the AI moderator?\\n\\nYes, you can customize the behavior of the AI moderator by modifying the config.yaml file. You can change the name of the bot, define trigger words, and add predefined personalities to give the bot a specific character.\\n\\n### 2\\\\. Can the AI moderator handle multiple conversations in a group chat setup?\\n\\nYes, the AI moderator is designed to handle group chat setups. It can understand the context of the conversation and respond accordingly, even when multiple people are talking at the same time.\\n\\n### 3\\\\. How does the AI moderator retrieve knowledge from different sources?\\n\\nThe AI moderator can retrieve knowledge from various sources, such as your YouTube channel, GitHub repository, and the internet. It uses a combination of knowledge retrieval techniques and online research tools to gather relevant information.\\n\\n### 4\\\\. Can the AI moderator generate reports and share AI trends?\\n\\nYes, the AI moderator can generate reports and share the latest AI trends. It can retrieve information from GitHub, filter out projects related to generative AI, and write reports to keep the community updated.\\n\\n### 5\\\\. How can I deploy the AI moderator on a cloud service?\\n\\nTo deploy the AI moderator on a cloud service, you can use platforms like Render. Simply upload your project to GitHub, create a new web service on Render, and configure the necessary environment variables. Render will handle the deployment and ensure your AI moderator stays active.\\n\\nRelated articles\\n----------------\\n\\n[Browse all articles](/)\\n\\n[AI Agent\\\\\\n\\\\\\n### How to reduce 78%+ of LLM Cost\\\\\\n\\\\\\n![How to reduce 78%+ of LLM Cost](https://assets-global.website-files.com/647a9c825f099afe643b5c78/65bedbda9969f366afdfad25_tiktok%20(1).jpg)](/learning-ai/how-to-reduce-llm-cost)\\n\\n[AI Agent\\\\\\n\\\\\\n### GPT5 unlocks LLM System 2 Thinking?\\\\\\n\\\\\\n![GPT5 unlocks LLM System 2 Thinking?\\\\\\n](https://assets-global.website-files.com/647a9c825f099afe643b5c78/65bedd7f060ee7802639f834_tiktok%20(2).jpg)](/learning-ai/gpt5-llm)\\n\\n[AI Agent\\\\\\n\\\\\\n### Research agent 3.0 - Build a group of AI researchers - Step by Step Tutorial\\\\\\n\\\\\\n![Research agent 3.0 - Build a group of AI researchers - Step by Step Tutorial](https://assets-global.website-files.com/647a9c825f099afe643b5c78/65bedeabdecca18351fc45d0_tiktok%20(3).jpg)](/learning-ai/how-to-build-ai-agent-tutorial-3)\\n\\n### Need help building your AI apps?\\n\\nI can help you on building AI apps or give trainings\\n\\n[Tell me about your AI app ideas](mailto:jason.zhou.design@gmail.com)\\n\\n[\\ue82e](https://www.youtube.com/@AIJason-oc8wb)\\n[\\ue829](https://twitter.com/jasonzhou1993)\\n[\\ue819](https://www.linkedin.com/in/jasonzhoudesign/)\\n\\nAI Jason\\n\\n100K subscribers\\n\\n[AI agent manages community 24/7 - Build Agent workforce ep#1](https://www.youtube.com/watch?v=yhBiVrigWNI)\\n\\nAI Jason\\n\\nSearch\\n\\nInfo\\n\\nShopping\\n\\nTap to unmute\\n\\nIf playback doesn\\'t begin shortly, try restarting your device.\\n\\nShare\\n\\nInclude playlist\\n\\nAn error occurred while retrieving sharing information. Please try again later.\\n\\nWatch later\\n\\nShare\\n\\nCopy link\\n\\nWatch on\\n\\n0:00\\n\\n/ â€¢Live\\n\\nâ€¢\\n\\n[](https://www.youtube.com/watch?v=yhBiVrigWNI \"Watch on YouTube\")', metadata={'title': 'How to Build Agent workforce Tutorial- AI agent manages community 24/7', 'description': 'AI Agent,', 'ogTitle': 'How to Build Agent workforce Tutorial- AI agent manages community 24/7', 'ogDescription': 'AI Agent,', 'ogImage': 'https://assets-global.website-files.com/647a9c825f099afe643b5c78/65bee17260bcfa83d917651f_tiktok%20(6).jpg', 'ogLocaleAlternate': [], 'sourceURL': 'https://www.ai-jason.com/learning-ai/ai-agent-tutorial-2'})]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_docs =[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_split = text_splitter.split_documents(docs_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'title': 'How to reduce 78%+ of LLM Cost', 'description': 'AI Agent, Real cost of LLM', 'ogTitle': 'How to reduce 78%+ of LLM Cost', 'ogDescription': 'AI Agent, Real cost of LLM', 'ogImage': 'https://assets-global.website-files.com/647a9c825f099afe643b5c78/65bedbda9969f366afdfad25_tiktok%20(1).jpg', 'sourceURL': 'https://www.ai-jason.com/learning-ai/how-to-reduce-llm-cost'}\n",
      "{'title': 'How to reduce 78%+ of LLM Cost', 'description': 'AI Agent, Real cost of LLM', 'ogTitle': 'How to reduce 78%+ of LLM Cost', 'ogDescription': 'AI Agent, Real cost of LLM', 'ogImage': 'https://assets-global.website-files.com/647a9c825f099afe643b5c78/65bedbda9969f366afdfad25_tiktok%20(1).jpg', 'sourceURL': 'https://www.ai-jason.com/learning-ai/how-to-reduce-llm-cost'}\n",
      "{'title': 'How to reduce 78%+ of LLM Cost', 'description': 'AI Agent, Real cost of LLM', 'ogTitle': 'How to reduce 78%+ of LLM Cost', 'ogDescription': 'AI Agent, Real cost of LLM', 'ogImage': 'https://assets-global.website-files.com/647a9c825f099afe643b5c78/65bedbda9969f366afdfad25_tiktok%20(1).jpg', 'sourceURL': 'https://www.ai-jason.com/learning-ai/how-to-reduce-llm-cost'}\n",
      "{'title': 'How to reduce 78%+ of LLM Cost', 'description': 'AI Agent, Real cost of LLM', 'ogTitle': 'How to reduce 78%+ of LLM Cost', 'ogDescription': 'AI Agent, Real cost of LLM', 'ogImage': 'https://assets-global.website-files.com/647a9c825f099afe643b5c78/65bedbda9969f366afdfad25_tiktok%20(1).jpg', 'sourceURL': 'https://www.ai-jason.com/learning-ai/how-to-reduce-llm-cost'}\n",
      "{'title': 'How to reduce 78%+ of LLM Cost', 'description': 'AI Agent, Real cost of LLM', 'ogTitle': 'How to reduce 78%+ of LLM Cost', 'ogDescription': 'AI Agent, Real cost of LLM', 'ogImage': 'https://assets-global.website-files.com/647a9c825f099afe643b5c78/65bedbda9969f366afdfad25_tiktok%20(1).jpg', 'sourceURL': 'https://www.ai-jason.com/learning-ai/how-to-reduce-llm-cost'}\n",
      "{'title': 'How to reduce 78%+ of LLM Cost', 'description': 'AI Agent, Real cost of LLM', 'ogTitle': 'How to reduce 78%+ of LLM Cost', 'ogDescription': 'AI Agent, Real cost of LLM', 'ogImage': 'https://assets-global.website-files.com/647a9c825f099afe643b5c78/65bedbda9969f366afdfad25_tiktok%20(1).jpg', 'sourceURL': 'https://www.ai-jason.com/learning-ai/how-to-reduce-llm-cost'}\n",
      "{'title': 'How to reduce 78%+ of LLM Cost', 'description': 'AI Agent, Real cost of LLM', 'ogTitle': 'How to reduce 78%+ of LLM Cost', 'ogDescription': 'AI Agent, Real cost of LLM', 'ogImage': 'https://assets-global.website-files.com/647a9c825f099afe643b5c78/65bedbda9969f366afdfad25_tiktok%20(1).jpg', 'sourceURL': 'https://www.ai-jason.com/learning-ai/how-to-reduce-llm-cost'}\n",
      "{'title': 'How to reduce 78%+ of LLM Cost', 'description': 'AI Agent, Real cost of LLM', 'ogTitle': 'How to reduce 78%+ of LLM Cost', 'ogDescription': 'AI Agent, Real cost of LLM', 'ogImage': 'https://assets-global.website-files.com/647a9c825f099afe643b5c78/65bedbda9969f366afdfad25_tiktok%20(1).jpg', 'sourceURL': 'https://www.ai-jason.com/learning-ai/how-to-reduce-llm-cost'}\n",
      "{'title': 'How to reduce 78%+ of LLM Cost', 'description': 'AI Agent, Real cost of LLM', 'ogTitle': 'How to reduce 78%+ of LLM Cost', 'ogDescription': 'AI Agent, Real cost of LLM', 'ogImage': 'https://assets-global.website-files.com/647a9c825f099afe643b5c78/65bedbda9969f366afdfad25_tiktok%20(1).jpg', 'sourceURL': 'https://www.ai-jason.com/learning-ai/how-to-reduce-llm-cost'}\n",
      "{'title': 'How to reduce 78%+ of LLM Cost', 'description': 'AI Agent, Real cost of LLM', 'ogTitle': 'How to reduce 78%+ of LLM Cost', 'ogDescription': 'AI Agent, Real cost of LLM', 'ogImage': 'https://assets-global.website-files.com/647a9c825f099afe643b5c78/65bedbda9969f366afdfad25_tiktok%20(1).jpg', 'sourceURL': 'https://www.ai-jason.com/learning-ai/how-to-reduce-llm-cost'}\n",
      "{'title': 'How to reduce 78%+ of LLM Cost', 'description': 'AI Agent, Real cost of LLM', 'ogTitle': 'How to reduce 78%+ of LLM Cost', 'ogDescription': 'AI Agent, Real cost of LLM', 'ogImage': 'https://assets-global.website-files.com/647a9c825f099afe643b5c78/65bedbda9969f366afdfad25_tiktok%20(1).jpg', 'sourceURL': 'https://www.ai-jason.com/learning-ai/how-to-reduce-llm-cost'}\n",
      "{'title': 'GPT5 unlocks LLM System 2 Thinking?', 'description': 'AI Agent,', 'ogTitle': 'GPT5 unlocks LLM System 2 Thinking?', 'ogDescription': 'AI Agent,', 'ogImage': 'https://assets-global.website-files.com/647a9c825f099afe643b5c78/65bedd7f060ee7802639f834_tiktok%20(2).jpg', 'sourceURL': 'https://www.ai-jason.com/learning-ai/gpt5-llm'}\n",
      "{'title': 'GPT5 unlocks LLM System 2 Thinking?', 'description': 'AI Agent,', 'ogTitle': 'GPT5 unlocks LLM System 2 Thinking?', 'ogDescription': 'AI Agent,', 'ogImage': 'https://assets-global.website-files.com/647a9c825f099afe643b5c78/65bedd7f060ee7802639f834_tiktok%20(2).jpg', 'sourceURL': 'https://www.ai-jason.com/learning-ai/gpt5-llm'}\n",
      "{'title': 'GPT5 unlocks LLM System 2 Thinking?', 'description': 'AI Agent,', 'ogTitle': 'GPT5 unlocks LLM System 2 Thinking?', 'ogDescription': 'AI Agent,', 'ogImage': 'https://assets-global.website-files.com/647a9c825f099afe643b5c78/65bedd7f060ee7802639f834_tiktok%20(2).jpg', 'sourceURL': 'https://www.ai-jason.com/learning-ai/gpt5-llm'}\n",
      "{'title': 'GPT5 unlocks LLM System 2 Thinking?', 'description': 'AI Agent,', 'ogTitle': 'GPT5 unlocks LLM System 2 Thinking?', 'ogDescription': 'AI Agent,', 'ogImage': 'https://assets-global.website-files.com/647a9c825f099afe643b5c78/65bedd7f060ee7802639f834_tiktok%20(2).jpg', 'sourceURL': 'https://www.ai-jason.com/learning-ai/gpt5-llm'}\n",
      "{'title': 'GPT5 unlocks LLM System 2 Thinking?', 'description': 'AI Agent,', 'ogTitle': 'GPT5 unlocks LLM System 2 Thinking?', 'ogDescription': 'AI Agent,', 'ogImage': 'https://assets-global.website-files.com/647a9c825f099afe643b5c78/65bedd7f060ee7802639f834_tiktok%20(2).jpg', 'sourceURL': 'https://www.ai-jason.com/learning-ai/gpt5-llm'}\n",
      "{'title': 'GPT5 unlocks LLM System 2 Thinking?', 'description': 'AI Agent,', 'ogTitle': 'GPT5 unlocks LLM System 2 Thinking?', 'ogDescription': 'AI Agent,', 'ogImage': 'https://assets-global.website-files.com/647a9c825f099afe643b5c78/65bedd7f060ee7802639f834_tiktok%20(2).jpg', 'sourceURL': 'https://www.ai-jason.com/learning-ai/gpt5-llm'}\n",
      "{'title': 'GPT5 unlocks LLM System 2 Thinking?', 'description': 'AI Agent,', 'ogTitle': 'GPT5 unlocks LLM System 2 Thinking?', 'ogDescription': 'AI Agent,', 'ogImage': 'https://assets-global.website-files.com/647a9c825f099afe643b5c78/65bedd7f060ee7802639f834_tiktok%20(2).jpg', 'sourceURL': 'https://www.ai-jason.com/learning-ai/gpt5-llm'}\n",
      "{'title': 'GPT5 unlocks LLM System 2 Thinking?', 'description': 'AI Agent,', 'ogTitle': 'GPT5 unlocks LLM System 2 Thinking?', 'ogDescription': 'AI Agent,', 'ogImage': 'https://assets-global.website-files.com/647a9c825f099afe643b5c78/65bedd7f060ee7802639f834_tiktok%20(2).jpg', 'sourceURL': 'https://www.ai-jason.com/learning-ai/gpt5-llm'}\n",
      "{'title': 'GPT5 unlocks LLM System 2 Thinking?', 'description': 'AI Agent,', 'ogTitle': 'GPT5 unlocks LLM System 2 Thinking?', 'ogDescription': 'AI Agent,', 'ogImage': 'https://assets-global.website-files.com/647a9c825f099afe643b5c78/65bedd7f060ee7802639f834_tiktok%20(2).jpg', 'sourceURL': 'https://www.ai-jason.com/learning-ai/gpt5-llm'}\n",
      "{'title': 'GPT5 unlocks LLM System 2 Thinking?', 'description': 'AI Agent,', 'ogTitle': 'GPT5 unlocks LLM System 2 Thinking?', 'ogDescription': 'AI Agent,', 'ogImage': 'https://assets-global.website-files.com/647a9c825f099afe643b5c78/65bedd7f060ee7802639f834_tiktok%20(2).jpg', 'sourceURL': 'https://www.ai-jason.com/learning-ai/gpt5-llm'}\n",
      "{'title': 'GPT5 unlocks LLM System 2 Thinking?', 'description': 'AI Agent,', 'ogTitle': 'GPT5 unlocks LLM System 2 Thinking?', 'ogDescription': 'AI Agent,', 'ogImage': 'https://assets-global.website-files.com/647a9c825f099afe643b5c78/65bedd7f060ee7802639f834_tiktok%20(2).jpg', 'sourceURL': 'https://www.ai-jason.com/learning-ai/gpt5-llm'}\n",
      "{'title': 'GPT5 unlocks LLM System 2 Thinking?', 'description': 'AI Agent,', 'ogTitle': 'GPT5 unlocks LLM System 2 Thinking?', 'ogDescription': 'AI Agent,', 'ogImage': 'https://assets-global.website-files.com/647a9c825f099afe643b5c78/65bedd7f060ee7802639f834_tiktok%20(2).jpg', 'sourceURL': 'https://www.ai-jason.com/learning-ai/gpt5-llm'}\n",
      "{'title': 'GPT5 unlocks LLM System 2 Thinking?', 'description': 'AI Agent,', 'ogTitle': 'GPT5 unlocks LLM System 2 Thinking?', 'ogDescription': 'AI Agent,', 'ogImage': 'https://assets-global.website-files.com/647a9c825f099afe643b5c78/65bedd7f060ee7802639f834_tiktok%20(2).jpg', 'sourceURL': 'https://www.ai-jason.com/learning-ai/gpt5-llm'}\n",
      "{'title': 'How to Build Agent workforce Tutorial- AI agent manages community 24/7', 'description': 'AI Agent,', 'ogTitle': 'How to Build Agent workforce Tutorial- AI agent manages community 24/7', 'ogDescription': 'AI Agent,', 'ogImage': 'https://assets-global.website-files.com/647a9c825f099afe643b5c78/65bee17260bcfa83d917651f_tiktok%20(6).jpg', 'sourceURL': 'https://www.ai-jason.com/learning-ai/ai-agent-tutorial-2'}\n",
      "{'title': 'How to Build Agent workforce Tutorial- AI agent manages community 24/7', 'description': 'AI Agent,', 'ogTitle': 'How to Build Agent workforce Tutorial- AI agent manages community 24/7', 'ogDescription': 'AI Agent,', 'ogImage': 'https://assets-global.website-files.com/647a9c825f099afe643b5c78/65bee17260bcfa83d917651f_tiktok%20(6).jpg', 'sourceURL': 'https://www.ai-jason.com/learning-ai/ai-agent-tutorial-2'}\n",
      "{'title': 'How to Build Agent workforce Tutorial- AI agent manages community 24/7', 'description': 'AI Agent,', 'ogTitle': 'How to Build Agent workforce Tutorial- AI agent manages community 24/7', 'ogDescription': 'AI Agent,', 'ogImage': 'https://assets-global.website-files.com/647a9c825f099afe643b5c78/65bee17260bcfa83d917651f_tiktok%20(6).jpg', 'sourceURL': 'https://www.ai-jason.com/learning-ai/ai-agent-tutorial-2'}\n",
      "{'title': 'How to Build Agent workforce Tutorial- AI agent manages community 24/7', 'description': 'AI Agent,', 'ogTitle': 'How to Build Agent workforce Tutorial- AI agent manages community 24/7', 'ogDescription': 'AI Agent,', 'ogImage': 'https://assets-global.website-files.com/647a9c825f099afe643b5c78/65bee17260bcfa83d917651f_tiktok%20(6).jpg', 'sourceURL': 'https://www.ai-jason.com/learning-ai/ai-agent-tutorial-2'}\n",
      "{'title': 'How to Build Agent workforce Tutorial- AI agent manages community 24/7', 'description': 'AI Agent,', 'ogTitle': 'How to Build Agent workforce Tutorial- AI agent manages community 24/7', 'ogDescription': 'AI Agent,', 'ogImage': 'https://assets-global.website-files.com/647a9c825f099afe643b5c78/65bee17260bcfa83d917651f_tiktok%20(6).jpg', 'sourceURL': 'https://www.ai-jason.com/learning-ai/ai-agent-tutorial-2'}\n",
      "{'title': 'How to Build Agent workforce Tutorial- AI agent manages community 24/7', 'description': 'AI Agent,', 'ogTitle': 'How to Build Agent workforce Tutorial- AI agent manages community 24/7', 'ogDescription': 'AI Agent,', 'ogImage': 'https://assets-global.website-files.com/647a9c825f099afe643b5c78/65bee17260bcfa83d917651f_tiktok%20(6).jpg', 'sourceURL': 'https://www.ai-jason.com/learning-ai/ai-agent-tutorial-2'}\n",
      "{'title': 'How to Build Agent workforce Tutorial- AI agent manages community 24/7', 'description': 'AI Agent,', 'ogTitle': 'How to Build Agent workforce Tutorial- AI agent manages community 24/7', 'ogDescription': 'AI Agent,', 'ogImage': 'https://assets-global.website-files.com/647a9c825f099afe643b5c78/65bee17260bcfa83d917651f_tiktok%20(6).jpg', 'sourceURL': 'https://www.ai-jason.com/learning-ai/ai-agent-tutorial-2'}\n",
      "{'title': 'How to Build Agent workforce Tutorial- AI agent manages community 24/7', 'description': 'AI Agent,', 'ogTitle': 'How to Build Agent workforce Tutorial- AI agent manages community 24/7', 'ogDescription': 'AI Agent,', 'ogImage': 'https://assets-global.website-files.com/647a9c825f099afe643b5c78/65bee17260bcfa83d917651f_tiktok%20(6).jpg', 'sourceURL': 'https://www.ai-jason.com/learning-ai/ai-agent-tutorial-2'}\n",
      "{'title': 'How to Build Agent workforce Tutorial- AI agent manages community 24/7', 'description': 'AI Agent,', 'ogTitle': 'How to Build Agent workforce Tutorial- AI agent manages community 24/7', 'ogDescription': 'AI Agent,', 'ogImage': 'https://assets-global.website-files.com/647a9c825f099afe643b5c78/65bee17260bcfa83d917651f_tiktok%20(6).jpg', 'sourceURL': 'https://www.ai-jason.com/learning-ai/ai-agent-tutorial-2'}\n",
      "{'title': 'How to Build Agent workforce Tutorial- AI agent manages community 24/7', 'description': 'AI Agent,', 'ogTitle': 'How to Build Agent workforce Tutorial- AI agent manages community 24/7', 'ogDescription': 'AI Agent,', 'ogImage': 'https://assets-global.website-files.com/647a9c825f099afe643b5c78/65bee17260bcfa83d917651f_tiktok%20(6).jpg', 'sourceURL': 'https://www.ai-jason.com/learning-ai/ai-agent-tutorial-2'}\n",
      "{'title': 'How to Build Agent workforce Tutorial- AI agent manages community 24/7', 'description': 'AI Agent,', 'ogTitle': 'How to Build Agent workforce Tutorial- AI agent manages community 24/7', 'ogDescription': 'AI Agent,', 'ogImage': 'https://assets-global.website-files.com/647a9c825f099afe643b5c78/65bee17260bcfa83d917651f_tiktok%20(6).jpg', 'sourceURL': 'https://www.ai-jason.com/learning-ai/ai-agent-tutorial-2'}\n",
      "{'title': 'How to Build Agent workforce Tutorial- AI agent manages community 24/7', 'description': 'AI Agent,', 'ogTitle': 'How to Build Agent workforce Tutorial- AI agent manages community 24/7', 'ogDescription': 'AI Agent,', 'ogImage': 'https://assets-global.website-files.com/647a9c825f099afe643b5c78/65bee17260bcfa83d917651f_tiktok%20(6).jpg', 'sourceURL': 'https://www.ai-jason.com/learning-ai/ai-agent-tutorial-2'}\n",
      "{'title': 'How to Build Agent workforce Tutorial- AI agent manages community 24/7', 'description': 'AI Agent,', 'ogTitle': 'How to Build Agent workforce Tutorial- AI agent manages community 24/7', 'ogDescription': 'AI Agent,', 'ogImage': 'https://assets-global.website-files.com/647a9c825f099afe643b5c78/65bee17260bcfa83d917651f_tiktok%20(6).jpg', 'sourceURL': 'https://www.ai-jason.com/learning-ai/ai-agent-tutorial-2'}\n",
      "{'title': 'How to Build Agent workforce Tutorial- AI agent manages community 24/7', 'description': 'AI Agent,', 'ogTitle': 'How to Build Agent workforce Tutorial- AI agent manages community 24/7', 'ogDescription': 'AI Agent,', 'ogImage': 'https://assets-global.website-files.com/647a9c825f099afe643b5c78/65bee17260bcfa83d917651f_tiktok%20(6).jpg', 'sourceURL': 'https://www.ai-jason.com/learning-ai/ai-agent-tutorial-2'}\n",
      "{'title': 'How to Build Agent workforce Tutorial- AI agent manages community 24/7', 'description': 'AI Agent,', 'ogTitle': 'How to Build Agent workforce Tutorial- AI agent manages community 24/7', 'ogDescription': 'AI Agent,', 'ogImage': 'https://assets-global.website-files.com/647a9c825f099afe643b5c78/65bee17260bcfa83d917651f_tiktok%20(6).jpg', 'sourceURL': 'https://www.ai-jason.com/learning-ai/ai-agent-tutorial-2'}\n",
      "{'title': 'How to Build Agent workforce Tutorial- AI agent manages community 24/7', 'description': 'AI Agent,', 'ogTitle': 'How to Build Agent workforce Tutorial- AI agent manages community 24/7', 'ogDescription': 'AI Agent,', 'ogImage': 'https://assets-global.website-files.com/647a9c825f099afe643b5c78/65bee17260bcfa83d917651f_tiktok%20(6).jpg', 'sourceURL': 'https://www.ai-jason.com/learning-ai/ai-agent-tutorial-2'}\n"
     ]
    }
   ],
   "source": [
    "for doc in doc_split:\n",
    "    if isinstance(doc, Document) and hasattr(doc, 'metadata'):\n",
    "        clean_metadata = {k:v for k,v in doc.metadata.items() if isinstance(v, (str, int, float, bool)) and len(v) > 0}\n",
    "        print(clean_metadata)\n",
    "        filtered_docs.append(Document(page_content=doc.page_content,metadata=clean_metadata))\n",
    "                                      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content=\"[AI JASON](/)\\n\\nCategories\\n\\n\\ue80f\\n\\n[AI Agent](/ai/ai-agent)\\n\\n[AI Automation Tutorials](/ai/ai-automation-tutorials)\\n\\n[Langchain Tutorials](/ai/langchain-tutorial)\\n\\n[Auto GPT Tutorials](/ai/auto-gpt-tutorial)\\n\\n[Contact](/contact)\\n\\n[\\ue82e](https://www.youtube.com/@AIJason-oc8wb)\\n[\\ue829](https://twitter.com/jasonzhou1993)\\n[\\ue819](https://www.linkedin.com/in/jasonzhoudesign/)\\n\\n[AI Agent](/ai/ai-agent)\\n\\nHow to reduce 78%+ of LLM Cost\\n==============================\\n\\nHow to reduce 78%+ of LLM Cost\\n==============================\\n\\nAre you building AI agents or using chatGPT? If so, you may be facing the challenge of high costs associated with large language models (LLM). In this article, we will explore effective strategies to reduce LLM costs by up to 78%. Let's dive in!\\n\\n\\u200d\\n\\n1\\\\. Change Model\\n----------------\", metadata={'title': 'How to reduce 78%+ of LLM Cost', 'description': 'AI Agent, Real cost of LLM', 'ogTitle': 'How to reduce 78%+ of LLM Cost', 'ogDescription': 'AI Agent, Real cost of LLM', 'ogImage': 'https://assets-global.website-files.com/647a9c825f099afe643b5c78/65bedbda9969f366afdfad25_tiktok%20(1).jpg', 'sourceURL': 'https://www.ai-jason.com/learning-ai/how-to-reduce-llm-cost'}),\n",
       " Document(page_content='One effective way to reduce LLM costs is to change the model you are using. Different models have different costs associated with them. For example, GPT-4 is the most powerful but also the most expensive model, while Mistro 7B is significantly cheaper. By using a smaller model for specific tasks and reserving the more expensive model for complex questions, you can achieve significant cost savings.\\n\\n![](https://assets-global.website-files.com/647a9c825f099afe643b5c78/65bedacac82767caefbdf0a0_1.jpg)\\n\\n2\\\\. Large Language Model Router\\n-------------------------------\\n\\nThe concept of a large language model router involves using a cascade of models to handle different types of questions. Cheaper models are used first, and if they are unable to provide a satisfactory answer, the question is passed on to a more expensive model. This approach leverages the significant cost difference between models and can result in substantial cost savings.', metadata={'title': 'How to reduce 78%+ of LLM Cost', 'description': 'AI Agent, Real cost of LLM', 'ogTitle': 'How to reduce 78%+ of LLM Cost', 'ogDescription': 'AI Agent, Real cost of LLM', 'ogImage': 'https://assets-global.website-files.com/647a9c825f099afe643b5c78/65bedbda9969f366afdfad25_tiktok%20(1).jpg', 'sourceURL': 'https://www.ai-jason.com/learning-ai/how-to-reduce-llm-cost'}),\n",
       " Document(page_content='![](https://assets-global.website-files.com/647a9c825f099afe643b5c78/65bedae566010ad14fe382cd_llm%20router.jpg)\\n\\n3\\\\. Multi-Agent Setup\\n---------------------\\n\\nAnother strategy is to set up multiple agents, each using a different model. The first agent attempts to complete the task using a cheaper model, and if it fails, the next agent is invoked. By using this multi-agent setup, you can achieve similar or even better success rates while significantly reducing costs.\\n\\n![](https://assets-global.website-files.com/647a9c825f099afe643b5c78/65bedaefa7461fca4f82df51_autogen.jpg)\\n\\n4\\\\. LLM Lingua\\n--------------\\n\\nLLM Lingua is a method introduced by Microsoft that focuses on optimizing the input and output of large language models. By removing unnecessary tokens and words from the input, you can significantly reduce the cost of running the model. This method is particularly effective for tasks such as summarization or answering specific questions based on a transcript.', metadata={'title': 'How to reduce 78%+ of LLM Cost', 'description': 'AI Agent, Real cost of LLM', 'ogTitle': 'How to reduce 78%+ of LLM Cost', 'ogDescription': 'AI Agent, Real cost of LLM', 'ogImage': 'https://assets-global.website-files.com/647a9c825f099afe643b5c78/65bedbda9969f366afdfad25_tiktok%20(1).jpg', 'sourceURL': 'https://www.ai-jason.com/learning-ai/how-to-reduce-llm-cost'}),\n",
       " Document(page_content='![](https://assets-global.website-files.com/647a9c825f099afe643b5c78/65bedaf791724343e65da125_llm%20lingua.jpg)\\n\\n5\\\\. Optimize Agent Memory\\n-------------------------\\n\\nOptimizing agent memory is another way to reduce LLM costs. By carefully managing the amount of conversation history stored in memory, you can minimize the number of tokens required for each interaction. This can lead to significant cost savings, especially when dealing with long conversations.\\n\\n![](https://assets-global.website-files.com/647a9c825f099afe643b5c78/65bedb03355b5d49f9ac7f8e_memory%20opt.jpg)\\n\\n6\\\\. Observability\\n-----------------\\n\\nHaving a deep understanding of the cost patterns in your LLM application is crucial for effective cost optimization. By using observability platforms like L Smith, you can monitor and log the cost for each large language model. This allows you to identify areas where costs can be optimized and make informed decisions to reduce overall expenses.', metadata={'title': 'How to reduce 78%+ of LLM Cost', 'description': 'AI Agent, Real cost of LLM', 'ogTitle': 'How to reduce 78%+ of LLM Cost', 'ogDescription': 'AI Agent, Real cost of LLM', 'ogImage': 'https://assets-global.website-files.com/647a9c825f099afe643b5c78/65bedbda9969f366afdfad25_tiktok%20(1).jpg', 'sourceURL': 'https://www.ai-jason.com/learning-ai/how-to-reduce-llm-cost'}),\n",
       " Document(page_content='By implementing these strategies, you can reduce LLM costs by up to 78% or more. Remember, reducing costs while maintaining performance and user experience is a critical skill for AI startups. Stay proactive and continuously optimize your LLM usage to maximize efficiency and profitability.\\n\\n\\u200d\\n\\nGet free HubSpot AI For Marketers Course: [https://clickhubspot.com/xut](https://clickhubspot.com/xut)\\n\\nðŸ”— Links', metadata={'title': 'How to reduce 78%+ of LLM Cost', 'description': 'AI Agent, Real cost of LLM', 'ogTitle': 'How to reduce 78%+ of LLM Cost', 'ogDescription': 'AI Agent, Real cost of LLM', 'ogImage': 'https://assets-global.website-files.com/647a9c825f099afe643b5c78/65bedbda9969f366afdfad25_tiktok%20(1).jpg', 'sourceURL': 'https://www.ai-jason.com/learning-ai/how-to-reduce-llm-cost'}),\n",
       " Document(page_content='*   Follow me on twitter: [https://twitter.com/jasonzhou1993](https://twitter.com/jasonzhou1993)\\n    \\n*   Join my AI email list: [https://crafters.ai/](https://crafters.ai/)\\n    \\n*   My discord: [https://discord.gg/eZXprSaCDE](https://discord.gg/eZXprSaCDE)\\n    \\n*   Inbox Agent: [https://www.youtube.com/watch?v=Jv\\\\_e6Rt4vWE&t=23s&ab\\\\_channel=AIJason](https://www.youtube.com/watch?v=Jv_e6Rt4vWE&t=23s&ab_channel=AIJason)\\n    \\n*   Research Agent: [https://www.youtube.com/watch?v=ogQUlS7CkYA&t=299s&ab\\\\_channel=AIJason](https://www.youtube.com/watch?v=ogQUlS7CkYA&t=299s&ab_channel=AIJason)\\n    \\n*   James Brigg on Agent Memory: [https://www.pinecone.io/learn/series/langchain/langchain-conversational-memory/](https://www.pinecone.io/learn/series/langchain/langchain-conversational-memory/)', metadata={'title': 'How to reduce 78%+ of LLM Cost', 'description': 'AI Agent, Real cost of LLM', 'ogTitle': 'How to reduce 78%+ of LLM Cost', 'ogDescription': 'AI Agent, Real cost of LLM', 'ogImage': 'https://assets-global.website-files.com/647a9c825f099afe643b5c78/65bedbda9969f366afdfad25_tiktok%20(1).jpg', 'sourceURL': 'https://www.ai-jason.com/learning-ai/how-to-reduce-llm-cost'}),\n",
       " Document(page_content='*   Another video about details for LLM cost tracking: [https://www.youtube.com/watch?v=Alb2kjUzpZ8&ab\\\\_channel=LearnfromOpenSourcewithElie](https://www.youtube.com/watch?v=Alb2kjUzpZ8&ab_channel=LearnfromOpenSourcewithElie)', metadata={'title': 'How to reduce 78%+ of LLM Cost', 'description': 'AI Agent, Real cost of LLM', 'ogTitle': 'How to reduce 78%+ of LLM Cost', 'ogDescription': 'AI Agent, Real cost of LLM', 'ogImage': 'https://assets-global.website-files.com/647a9c825f099afe643b5c78/65bedbda9969f366afdfad25_tiktok%20(1).jpg', 'sourceURL': 'https://www.ai-jason.com/learning-ai/how-to-reduce-llm-cost'}),\n",
       " Document(page_content=\"\\u200d\\n\\nFrequently Asked Questions\\n--------------------------\\n\\n### Q: How can I determine which model is the most cost-effective for my AI application?\\n\\nA: To determine the most cost-effective model for your AI application, you should consider the specific tasks and requirements of your application. Evaluate the performance and cost trade-offs of different models and choose the one that best fits your needs.\\n\\n### Q: Are there any open-source solutions available for large language model routing?\\n\\nA: While there are no specific open-source solutions for large language model routing, you can explore frameworks like Hugging Face's Hugging GPT, which allows you to build your own routing logic using a large language model as a controller.\\n\\n### Q: How often should I monitor and optimize my LLM costs?\", metadata={'title': 'How to reduce 78%+ of LLM Cost', 'description': 'AI Agent, Real cost of LLM', 'ogTitle': 'How to reduce 78%+ of LLM Cost', 'ogDescription': 'AI Agent, Real cost of LLM', 'ogImage': 'https://assets-global.website-files.com/647a9c825f099afe643b5c78/65bedbda9969f366afdfad25_tiktok%20(1).jpg', 'sourceURL': 'https://www.ai-jason.com/learning-ai/how-to-reduce-llm-cost'}),\n",
       " Document(page_content='A: It is recommended to monitor and optimize your LLM costs regularly, especially as your usage and user base grow. Keep track of cost patterns, identify areas for improvement, and implement cost optimization strategies accordingly.\\n\\n### Q: Can I reduce LLM costs without compromising performance?\\n\\nA: Yes, it is possible to reduce LLM costs without compromising performance. By carefully selecting the right models for specific tasks, optimizing agent memory, and using techniques like LLM Lingua, you can achieve cost savings while maintaining high performance and user experience.\\n\\n### Q: Are there any other cost optimization methods for LLM that I should be aware of?\\n\\nA: While the methods mentioned in this article are effective for reducing LLM costs, there may be other innovative approaches and techniques available. Stay updated with the latest research and developments in the field to discover new cost optimization methods.\\n\\nRelated articles\\n----------------\\n\\n[Browse all articles](/)', metadata={'title': 'How to reduce 78%+ of LLM Cost', 'description': 'AI Agent, Real cost of LLM', 'ogTitle': 'How to reduce 78%+ of LLM Cost', 'ogDescription': 'AI Agent, Real cost of LLM', 'ogImage': 'https://assets-global.website-files.com/647a9c825f099afe643b5c78/65bedbda9969f366afdfad25_tiktok%20(1).jpg', 'sourceURL': 'https://www.ai-jason.com/learning-ai/how-to-reduce-llm-cost'}),\n",
       " Document(page_content='[AI Agent\\\\\\n\\\\\\n### GPT5 unlocks LLM System 2 Thinking?\\\\\\n\\\\\\n![GPT5 unlocks LLM System 2 Thinking?\\\\\\n](https://assets-global.website-files.com/647a9c825f099afe643b5c78/65bedd7f060ee7802639f834_tiktok%20(2).jpg)](/learning-ai/gpt5-llm)\\n\\n[AI Agent\\\\\\n\\\\\\n### Research agent 3.0 - Build a group of AI researchers - Step by Step Tutorial\\\\\\n\\\\\\n![Research agent 3.0 - Build a group of AI researchers - Step by Step Tutorial](https://assets-global.website-files.com/647a9c825f099afe643b5c78/65bedeabdecca18351fc45d0_tiktok%20(3).jpg)](/learning-ai/how-to-build-ai-agent-tutorial-3)\\n\\n[AI Agent\\\\\\n\\\\\\n### How to Build Agent workforce Tutorial- AI agent manages community 24/7\\\\\\n\\\\\\n![How to Build Agent workforce Tutorial- AI agent manages community 24/7](https://assets-global.website-files.com/647a9c825f099afe643b5c78/65bee17260bcfa83d917651f_tiktok%20(6).jpg)](/learning-ai/ai-agent-tutorial-2)\\n\\n### Need help building your AI apps?\\n\\nI can help you on building AI apps or give trainings', metadata={'title': 'How to reduce 78%+ of LLM Cost', 'description': 'AI Agent, Real cost of LLM', 'ogTitle': 'How to reduce 78%+ of LLM Cost', 'ogDescription': 'AI Agent, Real cost of LLM', 'ogImage': 'https://assets-global.website-files.com/647a9c825f099afe643b5c78/65bedbda9969f366afdfad25_tiktok%20(1).jpg', 'sourceURL': 'https://www.ai-jason.com/learning-ai/how-to-reduce-llm-cost'}),\n",
       " Document(page_content='[Tell me about your AI app ideas](mailto:jason.zhou.design@gmail.com)\\n\\n[\\ue82e](https://www.youtube.com/@AIJason-oc8wb)\\n[\\ue829](https://twitter.com/jasonzhou1993)\\n[\\ue819](https://www.linkedin.com/in/jasonzhoudesign/)\\n\\nAI Jason\\n\\n100K subscribers\\n\\n[The REAL cost of LLM (And How to reduce 78%+ of Cost)](https://www.youtube.com/watch?v=lHxl5SchjPA)\\n\\nAI Jason\\n\\nSearch\\n\\nInfo\\n\\nShopping\\n\\nTap to unmute\\n\\nIf playback doesn\\'t begin shortly, try restarting your device.\\n\\nShare\\n\\nInclude playlist\\n\\nAn error occurred while retrieving sharing information. Please try again later.\\n\\nWatch later\\n\\nShare\\n\\nCopy link\\n\\nWatch on\\n\\n0:00\\n\\n/ â€¢Live\\n\\nâ€¢\\n\\n[](https://www.youtube.com/watch?v=lHxl5SchjPA \"Watch on YouTube\")', metadata={'title': 'How to reduce 78%+ of LLM Cost', 'description': 'AI Agent, Real cost of LLM', 'ogTitle': 'How to reduce 78%+ of LLM Cost', 'ogDescription': 'AI Agent, Real cost of LLM', 'ogImage': 'https://assets-global.website-files.com/647a9c825f099afe643b5c78/65bedbda9969f366afdfad25_tiktok%20(1).jpg', 'sourceURL': 'https://www.ai-jason.com/learning-ai/how-to-reduce-llm-cost'}),\n",
       " Document(page_content='[AI JASON](/)\\n\\nCategories\\n\\n\\ue80f\\n\\n[AI Agent](/ai/ai-agent)\\n\\n[AI Automation Tutorials](/ai/ai-automation-tutorials)\\n\\n[Langchain Tutorials](/ai/langchain-tutorial)\\n\\n[Auto GPT Tutorials](/ai/auto-gpt-tutorial)\\n\\n[Contact](/contact)\\n\\n[\\ue82e](https://www.youtube.com/@AIJason-oc8wb)\\n[\\ue829](https://twitter.com/jasonzhou1993)\\n[\\ue819](https://www.linkedin.com/in/jasonzhoudesign/)\\n\\n[AI Agent](/ai/ai-agent)\\n\\nGPT5 unlocks LLM System 2 Thinking?\\n===================================\\n\\nGPT5 unlocks LLM System 2 Thinking?\\n===================================\\n\\nAI has come a long way in recent years, with large language models (LLMs) like GPT-4 impressing us with their ability to generate text. However, these models primarily rely on system one thinking, which is fast and intuitive but lacks the ability to break down complex problems into smaller steps and explore different options. This limitation has led researchers to focus on developing GPT-5 with enhanced reasoning abilities and reliability.', metadata={'title': 'GPT5 unlocks LLM System 2 Thinking?', 'description': 'AI Agent,', 'ogTitle': 'GPT5 unlocks LLM System 2 Thinking?', 'ogDescription': 'AI Agent,', 'ogImage': 'https://assets-global.website-files.com/647a9c825f099afe643b5c78/65bedd7f060ee7802639f834_tiktok%20(2).jpg', 'sourceURL': 'https://www.ai-jason.com/learning-ai/gpt5-llm'}),\n",
       " Document(page_content='The Two Modes of Thinking\\n-------------------------\\n\\nIn his book \"Thinking, Fast and Slow,\" Daniel Kahneman introduces the concept of two modes of thinking: system one and system two. System one thinking is our fast, intuitive brain that quickly provides answers based on memorized information. On the other hand, system two thinking is slower but more rational, requiring us to take time, calculate, and analyze before arriving at an answer.\\n\\nSimilarly, large language models like GPT-4 primarily rely on system one thinking. They predict the best next words based on the sequence of words they have seen before, without truly understanding the complex problems they are trying to solve.\\n\\n![](https://assets-global.website-files.com/img/image-placeholder.svg)\\n\\n\\u200d\\n\\nThe Limitations of GPT-4\\n------------------------', metadata={'title': 'GPT5 unlocks LLM System 2 Thinking?', 'description': 'AI Agent,', 'ogTitle': 'GPT5 unlocks LLM System 2 Thinking?', 'ogDescription': 'AI Agent,', 'ogImage': 'https://assets-global.website-files.com/647a9c825f099afe643b5c78/65bedd7f060ee7802639f834_tiktok%20(2).jpg', 'sourceURL': 'https://www.ai-jason.com/learning-ai/gpt5-llm'}),\n",
       " Document(page_content='GPT-4, despite its impressive capabilities, lacks system two thinking. It cannot break down complex tasks into smaller steps or explore different options. It simply generates text based on patterns it has learned from training data. This limitation becomes evident when GPT-4 is faced with complex problems that require deeper analysis and reasoning.\\n\\nFor example, in a video by Veritasium, college students were asked seemingly simple questions like the time it takes for the Earth to go around the Sun. Many of them answered incorrectly because they relied on system one thinking, providing automatic intuitive answers without truly considering the question.\\n\\nLarge language models like GPT-4 face a similar challenge. They lack the ability to think critically and break down complex problems into smaller, manageable steps. This is where GPT-5 comes in.\\n\\nThe Promise of GPT-5\\n--------------------', metadata={'title': 'GPT5 unlocks LLM System 2 Thinking?', 'description': 'AI Agent,', 'ogTitle': 'GPT5 unlocks LLM System 2 Thinking?', 'ogDescription': 'AI Agent,', 'ogImage': 'https://assets-global.website-files.com/647a9c825f099afe643b5c78/65bedd7f060ee7802639f834_tiktok%20(2).jpg', 'sourceURL': 'https://www.ai-jason.com/learning-ai/gpt5-llm'}),\n",
       " Document(page_content=\"GPT-5 aims to enhance the reasoning abilities of large language models and introduce system two thinking. OpenAI's Sam Altman mentioned in an interview with Bill Gates that the key milestones for GPT-5 will be around reasoning ability and reliability.\\n\\nCurrently, GPT-4 can reason in extremely limited ways and lacks reliability. It may provide correct answers, but it doesn't always know which answer is the best. GPT-5 aims to improve this by increasing reliability and enhancing reasoning abilities.\\n\\nAltman also mentioned the possibility of GPT-5 being able to solve complex math equations by applying transformations an arbitrary number of times. This would require a more complex control logic for reasoning, going beyond what is currently possible with GPT-4.\\n\\nHowever, simply improving the model itself is not enough. There are ways to enforce system two thinking in large language models today, even with GPT-4.\", metadata={'title': 'GPT5 unlocks LLM System 2 Thinking?', 'description': 'AI Agent,', 'ogTitle': 'GPT5 unlocks LLM System 2 Thinking?', 'ogDescription': 'AI Agent,', 'ogImage': 'https://assets-global.website-files.com/647a9c825f099afe643b5c78/65bedd7f060ee7802639f834_tiktok%20(2).jpg', 'sourceURL': 'https://www.ai-jason.com/learning-ai/gpt5-llm'}),\n",
       " Document(page_content='Promoting System 2 Thinking in Large Language Models\\n----------------------------------------------------\\n\\nThere are two common strategies to promote system two thinking in large language models: prompt engineering and communicative agents.\\n\\n### Prompt Engineering\\n\\nPrompt engineering is a simple and common method to guide large language models towards system two thinking. One approach is the \"chain of thought,\" where a sentence is inserted step by step before the model generates any text. This forces the model to break down the problem into smaller steps and think through each one.\\n\\nAnother approach is to provide a few short prompt examples instead of a step-by-step process. These examples guide the model towards thinking through different steps and considering multiple possibilities.', metadata={'title': 'GPT5 unlocks LLM System 2 Thinking?', 'description': 'AI Agent,', 'ogTitle': 'GPT5 unlocks LLM System 2 Thinking?', 'ogDescription': 'AI Agent,', 'ogImage': 'https://assets-global.website-files.com/647a9c825f099afe643b5c78/65bedd7f060ee7802639f834_tiktok%20(2).jpg', 'sourceURL': 'https://www.ai-jason.com/learning-ai/gpt5-llm'}),\n",
       " Document(page_content=\"While prompt engineering can be effective in promoting system two thinking, it has limitations. It often restricts the model to consider only one possibility and may not explore diverse options, similar to how humans approach creative problem-solving.\\n\\nTo address this limitation, more advanced prompting tactics like self-consistency with chain of thought (SCCOT) have been proposed. SCCOT involves running the chain of thought process multiple times and reviewing and voting on the most reasonable answers. This allows for some exploration of different options but requires more implementation effort.\\n\\nAnother advanced prompting tactic is the tree of sorts, which simulates a tree search to explore different options and paths. It keeps track of all the paths explored and allows for backtracking if the current path doesn't lead to the desired outcome. However, implementing the tree of sorts is complex and requires significant implementation effort.\\n\\n### Communicative Agents\", metadata={'title': 'GPT5 unlocks LLM System 2 Thinking?', 'description': 'AI Agent,', 'ogTitle': 'GPT5 unlocks LLM System 2 Thinking?', 'ogDescription': 'AI Agent,', 'ogImage': 'https://assets-global.website-files.com/647a9c825f099afe643b5c78/65bedd7f060ee7802639f834_tiktok%20(2).jpg', 'sourceURL': 'https://www.ai-jason.com/learning-ai/gpt5-llm'}),\n",
       " Document(page_content=\"Communicative agents provide an elegant solution to promote system two thinking in large language models. These are multi-agent setups where users can define different agents and simulate conversations between them. The agents can reflect and spot flaws in each other's perspectives and thinking processes.\\n\\nCommunicative agents have shown promise in enhancing system two thinking. They allow for dedicated agents to review and critique the model's answers, identifying flaws and providing feedback. This collaborative approach mimics how humans solve complex problems by exploring multiple options and learning from each other.\\n\\nSetting up communicative agents can be done using various frameworks like ChatGPT, MetaGPT, Autogen, and Crew AI. These frameworks enable the creation of agent workflows and facilitate conversations between agents with different roles, such as problem solvers and reviewers.\", metadata={'title': 'GPT5 unlocks LLM System 2 Thinking?', 'description': 'AI Agent,', 'ogTitle': 'GPT5 unlocks LLM System 2 Thinking?', 'ogDescription': 'AI Agent,', 'ogImage': 'https://assets-global.website-files.com/647a9c825f099afe643b5c78/65bedd7f060ee7802639f834_tiktok%20(2).jpg', 'sourceURL': 'https://www.ai-jason.com/learning-ai/gpt5-llm'}),\n",
       " Document(page_content='Autogen Studio, a no-code interface for Autogen, simplifies the setup of communicative agent workflows. It allows for easy collaboration and problem-solving between agents, making it accessible to a wider range of users.\\n\\nUnlocking System 2 Thinking with GPT-4 Today\\n--------------------------------------------\\n\\nWhile GPT-4 may not have native system two thinking capabilities, prompt engineering and communicative agents can be used to enforce system two thinking and solve complex tasks.\\n\\nPrompt engineering, such as the chain of thought or self-consistency with chain of thought, guides the model towards thinking through problems step by step and considering multiple possibilities. However, prompt engineering may limit exploration and diversity of solutions.', metadata={'title': 'GPT5 unlocks LLM System 2 Thinking?', 'description': 'AI Agent,', 'ogTitle': 'GPT5 unlocks LLM System 2 Thinking?', 'ogDescription': 'AI Agent,', 'ogImage': 'https://assets-global.website-files.com/647a9c825f099afe643b5c78/65bedd7f060ee7802639f834_tiktok%20(2).jpg', 'sourceURL': 'https://www.ai-jason.com/learning-ai/gpt5-llm'}),\n",
       " Document(page_content=\"Communicative agents, on the other hand, provide a collaborative approach to problem-solving. By simulating conversations between agents, users can leverage the strengths of system one and system two thinking. Reviewers can spot flaws in the model's answers, while problem solvers can iterate and improve their solutions based on feedback.\\n\\nFrameworks like Autogen Studio make it easy to set up communicative agent workflows, allowing for seamless collaboration and problem-solving.\\n\\nThe Future of GPT-5 and System 2 Thinking\\n-----------------------------------------\\n\\nGPT-5 holds the promise of unlocking system two thinking in large language models. With enhanced reasoning abilities and reliability, GPT-5 aims to bridge the gap between system one and system two thinking, enabling models to solve complex problems more effectively.\", metadata={'title': 'GPT5 unlocks LLM System 2 Thinking?', 'description': 'AI Agent,', 'ogTitle': 'GPT5 unlocks LLM System 2 Thinking?', 'ogDescription': 'AI Agent,', 'ogImage': 'https://assets-global.website-files.com/647a9c825f099afe643b5c78/65bedd7f060ee7802639f834_tiktok%20(2).jpg', 'sourceURL': 'https://www.ai-jason.com/learning-ai/gpt5-llm'}),\n",
       " Document(page_content=\"Researchers are actively working on developing GPT-5 with improved reasoning abilities. The focus is on enabling large language models to break down complex tasks, explore different options, and make more accurate and informed decisions.\\n\\nAs we look forward to the advancements in GPT-5, it's important to continue exploring and implementing strategies like prompt engineering and communicative agents to drive system two thinking in large language models today.\\n\\n\\u200d\\n\\nFollow me on twitter: [https://twitter.com/jasonzhou1993](https://twitter.com/jasonzhou1993)\\n\\n\\u200d\\n\\nFAQs\\n----\\n\\n### 1\\\\. Can GPT-4 solve complex problems?\\n\\nGPT-4 can generate text and provide answers, but it primarily relies on system one thinking. It lacks the ability to break down complex problems into smaller steps and explore different options.\\n\\n### 2\\\\. How can prompt engineering promote system two thinking?\", metadata={'title': 'GPT5 unlocks LLM System 2 Thinking?', 'description': 'AI Agent,', 'ogTitle': 'GPT5 unlocks LLM System 2 Thinking?', 'ogDescription': 'AI Agent,', 'ogImage': 'https://assets-global.website-files.com/647a9c825f099afe643b5c78/65bedd7f060ee7802639f834_tiktok%20(2).jpg', 'sourceURL': 'https://www.ai-jason.com/learning-ai/gpt5-llm'}),\n",
       " Document(page_content='Prompt engineering, such as the chain of thought or self-consistency with chain of thought, guides large language models towards thinking through problems step by step and considering multiple possibilities.\\n\\n### 3\\\\. What are communicative agents?\\n\\nCommunicative agents are multi-agent setups where users can define different agents and simulate conversations between them. This allows for collaborative problem-solving and promotes system two thinking.\\n\\n### 4\\\\. How can communicative agents be set up?\\n\\nFrameworks like Autogen Studio provide a no-code interface for setting up communicative agent workflows. Users can define agents, assign roles, and simulate conversations to solve complex problems.\\n\\n### 5\\\\. What is the future of GPT-5?\\n\\nGPT-5 aims to enhance reasoning abilities and bridge the gap between system one and system two thinking. It holds the promise of enabling large language models to solve complex problems more effectively.\\n\\nRelated articles\\n----------------', metadata={'title': 'GPT5 unlocks LLM System 2 Thinking?', 'description': 'AI Agent,', 'ogTitle': 'GPT5 unlocks LLM System 2 Thinking?', 'ogDescription': 'AI Agent,', 'ogImage': 'https://assets-global.website-files.com/647a9c825f099afe643b5c78/65bedd7f060ee7802639f834_tiktok%20(2).jpg', 'sourceURL': 'https://www.ai-jason.com/learning-ai/gpt5-llm'}),\n",
       " Document(page_content='[Browse all articles](/)\\n\\n[AI Agent\\\\\\n\\\\\\n### How to reduce 78%+ of LLM Cost\\\\\\n\\\\\\n![How to reduce 78%+ of LLM Cost](https://assets-global.website-files.com/647a9c825f099afe643b5c78/65bedbda9969f366afdfad25_tiktok%20(1).jpg)](/learning-ai/how-to-reduce-llm-cost)\\n\\n[AI Agent\\\\\\n\\\\\\n### Research agent 3.0 - Build a group of AI researchers - Step by Step Tutorial\\\\\\n\\\\\\n![Research agent 3.0 - Build a group of AI researchers - Step by Step Tutorial](https://assets-global.website-files.com/647a9c825f099afe643b5c78/65bedeabdecca18351fc45d0_tiktok%20(3).jpg)](/learning-ai/how-to-build-ai-agent-tutorial-3)\\n\\n[AI Agent\\\\\\n\\\\\\n### How to Build Agent workforce Tutorial- AI agent manages community 24/7\\\\\\n\\\\\\n![How to Build Agent workforce Tutorial- AI agent manages community 24/7](https://assets-global.website-files.com/647a9c825f099afe643b5c78/65bee17260bcfa83d917651f_tiktok%20(6).jpg)](/learning-ai/ai-agent-tutorial-2)\\n\\n### Need help building your AI apps?\\n\\nI can help you on building AI apps or give trainings', metadata={'title': 'GPT5 unlocks LLM System 2 Thinking?', 'description': 'AI Agent,', 'ogTitle': 'GPT5 unlocks LLM System 2 Thinking?', 'ogDescription': 'AI Agent,', 'ogImage': 'https://assets-global.website-files.com/647a9c825f099afe643b5c78/65bedd7f060ee7802639f834_tiktok%20(2).jpg', 'sourceURL': 'https://www.ai-jason.com/learning-ai/gpt5-llm'}),\n",
       " Document(page_content='[Tell me about your AI app ideas](mailto:jason.zhou.design@gmail.com)\\n\\n[\\ue82e](https://www.youtube.com/@AIJason-oc8wb)\\n[\\ue829](https://twitter.com/jasonzhou1993)\\n[\\ue819](https://www.linkedin.com/in/jasonzhoudesign/)\\n\\nAI Jason\\n\\n100K subscribers\\n\\n[GPT5 unlocks LLM System 2 Thinking?](https://www.youtube.com/watch?v=sD0X-lWPdxg)\\n\\nAI Jason\\n\\nSearch\\n\\nInfo\\n\\nShopping\\n\\nTap to unmute\\n\\nIf playback doesn\\'t begin shortly, try restarting your device.\\n\\nShare\\n\\nInclude playlist\\n\\nAn error occurred while retrieving sharing information. Please try again later.\\n\\nWatch later\\n\\nShare\\n\\nCopy link\\n\\nWatch on\\n\\n0:00\\n\\n/ â€¢Live\\n\\nâ€¢\\n\\n[](https://www.youtube.com/watch?v=sD0X-lWPdxg \"Watch on YouTube\")', metadata={'title': 'GPT5 unlocks LLM System 2 Thinking?', 'description': 'AI Agent,', 'ogTitle': 'GPT5 unlocks LLM System 2 Thinking?', 'ogDescription': 'AI Agent,', 'ogImage': 'https://assets-global.website-files.com/647a9c825f099afe643b5c78/65bedd7f060ee7802639f834_tiktok%20(2).jpg', 'sourceURL': 'https://www.ai-jason.com/learning-ai/gpt5-llm'}),\n",
       " Document(page_content='[AI JASON](/)\\n\\nCategories\\n\\n\\ue80f\\n\\n[AI Agent](/ai/ai-agent)\\n\\n[AI Automation Tutorials](/ai/ai-automation-tutorials)\\n\\n[Langchain Tutorials](/ai/langchain-tutorial)\\n\\n[Auto GPT Tutorials](/ai/auto-gpt-tutorial)\\n\\n[Contact](/contact)\\n\\n[\\ue82e](https://www.youtube.com/@AIJason-oc8wb)\\n[\\ue829](https://twitter.com/jasonzhou1993)\\n[\\ue819](https://www.linkedin.com/in/jasonzhoudesign/)\\n\\n[AI Agent](/ai/ai-agent)\\n\\nHow to Build Agent workforce Tutorial- AI agent manages community 24/7\\n======================================================================\\n\\nAI agent manages community 24/7 - Build Agent workforce\\n=======================================================', metadata={'title': 'How to Build Agent workforce Tutorial- AI agent manages community 24/7', 'description': 'AI Agent,', 'ogTitle': 'How to Build Agent workforce Tutorial- AI agent manages community 24/7', 'ogDescription': 'AI Agent,', 'ogImage': 'https://assets-global.website-files.com/647a9c825f099afe643b5c78/65bee17260bcfa83d917651f_tiktok%20(6).jpg', 'sourceURL': 'https://www.ai-jason.com/learning-ai/ai-agent-tutorial-2'}),\n",
       " Document(page_content='Are you overwhelmed with the amount of emails, messages, and tasks you need to handle every day? Do you wish you had a personal assistant to help you manage your workload? Well, thanks to advancements in artificial intelligence (AI), you can now build your own AI employees to take care of these tasks for you. In this series of videos, I will show you how to create AI agents that can act as your digital workforce, handling various roles and tasks.\\n\\nWhy Build AI Employees?\\n-----------------------', metadata={'title': 'How to Build Agent workforce Tutorial- AI agent manages community 24/7', 'description': 'AI Agent,', 'ogTitle': 'How to Build Agent workforce Tutorial- AI agent manages community 24/7', 'ogDescription': 'AI Agent,', 'ogImage': 'https://assets-global.website-files.com/647a9c825f099afe643b5c78/65bee17260bcfa83d917651f_tiktok%20(6).jpg', 'sourceURL': 'https://www.ai-jason.com/learning-ai/ai-agent-tutorial-2'}),\n",
       " Document(page_content='As a content creator with a growing YouTube channel, I found myself struggling to keep up with the influx of emails, messages from various platforms, and the need to stay on top of new purchases and video editing work. I considered outsourcing some of the work or hiring someone to help me, but then I had an idea. Instead of relying on others, why not build AI employees to handle these tasks? This would not only be an interesting experiment but also a way to push the boundaries of AI technology.\\n\\nBuilding AI employees is similar to building self-driving cars. While many researchers are focused on developing fully autonomous AI agents (level 5), there are plenty of opportunities to create AI agents that require some human guidance (level 3 or level 2). These AI agents can still deliver excellent results and are more feasible to build at this stage. My goal is not to create fully autonomous agents but to build AI employees that can get the work done with some guidance.', metadata={'title': 'How to Build Agent workforce Tutorial- AI agent manages community 24/7', 'description': 'AI Agent,', 'ogTitle': 'How to Build Agent workforce Tutorial- AI agent manages community 24/7', 'ogDescription': 'AI Agent,', 'ogImage': 'https://assets-global.website-files.com/647a9c825f099afe643b5c78/65bee17260bcfa83d917651f_tiktok%20(6).jpg', 'sourceURL': 'https://www.ai-jason.com/learning-ai/ai-agent-tutorial-2'}),\n",
       " Document(page_content=\"So, the first AI employee I want to build is a community moderator for my Discord community. As a content creator based in Australia, I have community members from different parts of the world with wildly different time zones. It's challenging for me to respond to messages in a timely manner. Ideally, I would love to have a community moderator who can proactively engage with people 24/7. This AI moderator should have deep domain knowledge in AI and software development, stay updated on AI trends, and engage with the community proactively.\\n\\nChallenges to Overcome\\n----------------------\", metadata={'title': 'How to Build Agent workforce Tutorial- AI agent manages community 24/7', 'description': 'AI Agent,', 'ogTitle': 'How to Build Agent workforce Tutorial- AI agent manages community 24/7', 'ogDescription': 'AI Agent,', 'ogImage': 'https://assets-global.website-files.com/647a9c825f099afe643b5c78/65bee17260bcfa83d917651f_tiktok%20(6).jpg', 'sourceURL': 'https://www.ai-jason.com/learning-ai/ai-agent-tutorial-2'}),\n",
       " Document(page_content='Building an AI community moderator comes with its own set of challenges. Firstly, how should the AI behave in a group chat setup? Most AI agents are designed for one-on-one conversations, but in a Discord community, there can be multiple people talking at the same time. Secondly, the AI moderator should have a long-term memory of each community member to make conversations feel more genuine and to connect community members with similar interests. Lastly, the AI moderator should be able to retrieve knowledge from various sources, such as my YouTube channel, GitHub repository, and the internet, to provide up-to-date information.', metadata={'title': 'How to Build Agent workforce Tutorial- AI agent manages community 24/7', 'description': 'AI Agent,', 'ogTitle': 'How to Build Agent workforce Tutorial- AI agent manages community 24/7', 'ogDescription': 'AI Agent,', 'ogImage': 'https://assets-global.website-files.com/647a9c825f099afe643b5c78/65bee17260bcfa83d917651f_tiktok%20(6).jpg', 'sourceURL': 'https://www.ai-jason.com/learning-ai/ai-agent-tutorial-2'}),\n",
       " Document(page_content='To overcome these challenges, I found an open-source project called Discord AI chatbot on GitHub. This project integrates OpenAI into a Discord bot, taking care of the network setup and providing design patterns for AI behavior in a group chat setup. It allows me to define trigger words that activate the AI moderator and retrieve the relevant conversation history. While this project has some limitations, such as limited conversation history and the inability to perform complex tasks, it provides a flexible foundation for customization.\\n\\n![](https://assets-global.website-files.com/647a9c825f099afe643b5c78/65bee0a5f2e303fd2cefe0b3_Copy%20of%20Your%20paragraph%20text.jpg)\\n\\nGetting Started: Installing Discord AI Chatbot\\n----------------------------------------------', metadata={'title': 'How to Build Agent workforce Tutorial- AI agent manages community 24/7', 'description': 'AI Agent,', 'ogTitle': 'How to Build Agent workforce Tutorial- AI agent manages community 24/7', 'ogDescription': 'AI Agent,', 'ogImage': 'https://assets-global.website-files.com/647a9c825f099afe643b5c78/65bee17260bcfa83d917651f_tiktok%20(6).jpg', 'sourceURL': 'https://www.ai-jason.com/learning-ai/ai-agent-tutorial-2'}),\n",
       " Document(page_content='To get started, you need to install the Discord AI chatbot. Once the AI chatbot is up and running, you can customize its behavior by modifying the config.yaml file. You can change the name of the bot, define trigger words, and add predefined personalities to give the bot a specific character.\\n\\nEnhancing the AI Moderator: Building an AI Agent\\n------------------------------------------------\\n\\nWhile the AI chatbot provides a good starting point, I wanted to create an AI moderator with more advanced capabilities. I wanted the AI moderator to have a long-term memory, retrieve knowledge from various sources, and schedule tasks. To achieve this, I used the Launching Agent framework and integrated it into the AI chatbot.', metadata={'title': 'How to Build Agent workforce Tutorial- AI agent manages community 24/7', 'description': 'AI Agent,', 'ogTitle': 'How to Build Agent workforce Tutorial- AI agent manages community 24/7', 'ogDescription': 'AI Agent,', 'ogImage': 'https://assets-global.website-files.com/647a9c825f099afe643b5c78/65bee17260bcfa83d917651f_tiktok%20(6).jpg', 'sourceURL': 'https://www.ai-jason.com/learning-ai/ai-agent-tutorial-2'}),\n",
       " Document(page_content=\"Firstly, I created a knowledge retrieval function to extract information from my YouTube channel, GitHub repository, and the internet. I used a platform called Random CI to turn my website into a knowledge base and used the Launching Agent's large language model to perform knowledge retrieval. I also implemented functions for online research, such as Google search and website scripting, to gather information from the internet.\\n\\nNext, I created a research agent that combines the knowledge retrieval function and online research tools. This research agent can search my internal knowledge base first and then perform online research if necessary. It can provide relevant information and links to answer questions from the community.\", metadata={'title': 'How to Build Agent workforce Tutorial- AI agent manages community 24/7', 'description': 'AI Agent,', 'ogTitle': 'How to Build Agent workforce Tutorial- AI agent manages community 24/7', 'ogDescription': 'AI Agent,', 'ogImage': 'https://assets-global.website-files.com/647a9c825f099afe643b5c78/65bee17260bcfa83d917651f_tiktok%20(6).jpg', 'sourceURL': 'https://www.ai-jason.com/learning-ai/ai-agent-tutorial-2'}),\n",
       " Document(page_content=\"To integrate the research agent into the AI chatbot, I modified the AI utility file. I updated the message handling function to pass the user's message to the research agent and added a mapping of agents for each user. This allows each user to have a unique chat history and memory. I also added a scheduler feature to trigger the research agent to generate GitHub reports every two days.\\n\\nGenerating GitHub Reports: Sharing AI Trends and News\\n-----------------------------------------------------\\n\\nIn addition to moderating the community, I wanted the AI agent to share the latest AI trends and news from various sources, such as Twitter, GitHub, and newsletters. For the initial MVP, I decided to generate GitHub reports every two days. The AI agent would check the GitHub trending page, filter out projects related to generative AI, and write a report to keep the community updated.\", metadata={'title': 'How to Build Agent workforce Tutorial- AI agent manages community 24/7', 'description': 'AI Agent,', 'ogTitle': 'How to Build Agent workforce Tutorial- AI agent manages community 24/7', 'ogDescription': 'AI Agent,', 'ogImage': 'https://assets-global.website-files.com/647a9c825f099afe643b5c78/65bee17260bcfa83d917651f_tiktok%20(6).jpg', 'sourceURL': 'https://www.ai-jason.com/learning-ai/ai-agent-tutorial-2'}),\n",
       " Document(page_content='To achieve this, I used a platform called BrowseAI to extract structured data from the GitHub trending page. BrowseAI allows me to define the elements I want to extract, such as the name of the repo, the link, and the number of stars. I integrated BrowseAI into the AI agent to script the GitHub trending page and retrieve the relevant information.\\n\\nI also implemented a scheduler feature in the AI chatbot to trigger the generation of GitHub reports every two days. This feature allows the AI agent to automatically post the reports in the Discord channels that have enabled the schedule task.\\n\\nDeployment and Continuous Operation\\n-----------------------------------', metadata={'title': 'How to Build Agent workforce Tutorial- AI agent manages community 24/7', 'description': 'AI Agent,', 'ogTitle': 'How to Build Agent workforce Tutorial- AI agent manages community 24/7', 'ogDescription': 'AI Agent,', 'ogImage': 'https://assets-global.website-files.com/647a9c825f099afe643b5c78/65bee17260bcfa83d917651f_tiktok%20(6).jpg', 'sourceURL': 'https://www.ai-jason.com/learning-ai/ai-agent-tutorial-2'}),\n",
       " Document(page_content='To ensure the AI moderator operates 24/7, you can deploy the AI chatbot on a cloud service. One option is to use Render, a platform that allows you to deploy web services. Simply upload your project to GitHub, create a new web service on Render, and configure the necessary environment variables. Render will handle the deployment and ensure your AI moderator stays active.\\n\\nHowever, keep in mind that free versions of cloud services may have limitations, such as inactivity timeouts. To prevent the AI moderator from going inactive, you can use uptime monitoring services like Uptime Robot to ping your API endpoint at regular intervals.\\n\\nWith your AI moderator deployed and continuously operational, you can enjoy the benefits of having a 24/7 community manager. The AI moderator will handle messages, answer questions, and share the latest AI trends and news, allowing you to focus on other aspects of your content creation.\\n\\nConclusion\\n----------', metadata={'title': 'How to Build Agent workforce Tutorial- AI agent manages community 24/7', 'description': 'AI Agent,', 'ogTitle': 'How to Build Agent workforce Tutorial- AI agent manages community 24/7', 'ogDescription': 'AI Agent,', 'ogImage': 'https://assets-global.website-files.com/647a9c825f099afe643b5c78/65bee17260bcfa83d917651f_tiktok%20(6).jpg', 'sourceURL': 'https://www.ai-jason.com/learning-ai/ai-agent-tutorial-2'}),\n",
       " Document(page_content='Building AI employees, such as a community moderator, can greatly enhance your productivity and efficiency. With the right tools and frameworks, you can create AI agents that handle various tasks and roles, providing a seamless experience for your community members. By combining knowledge retrieval, online research, and scheduling capabilities, you can build an AI moderator that stays engaged with your community 24/7.\\n\\nðŸ”— Links\\n\\n*   Github repo: [https://github.com/JayZeeDesign/Discord-AI-Chatbot](https://github.com/JayZeeDesign/Discord-AI-Chatbot)\\n    \\n*   Follow me on twitter: [https://twitter.com/jasonzhou1993](https://twitter.com/jasonzhou1993)\\n    \\n\\n\\u200d\\n\\nFrequently Asked Questions\\n--------------------------\\n\\n### 1\\\\. Can I customize the behavior of the AI moderator?\\n\\nYes, you can customize the behavior of the AI moderator by modifying the config.yaml file. You can change the name of the bot, define trigger words, and add predefined personalities to give the bot a specific character.', metadata={'title': 'How to Build Agent workforce Tutorial- AI agent manages community 24/7', 'description': 'AI Agent,', 'ogTitle': 'How to Build Agent workforce Tutorial- AI agent manages community 24/7', 'ogDescription': 'AI Agent,', 'ogImage': 'https://assets-global.website-files.com/647a9c825f099afe643b5c78/65bee17260bcfa83d917651f_tiktok%20(6).jpg', 'sourceURL': 'https://www.ai-jason.com/learning-ai/ai-agent-tutorial-2'}),\n",
       " Document(page_content='### 2\\\\. Can the AI moderator handle multiple conversations in a group chat setup?\\n\\nYes, the AI moderator is designed to handle group chat setups. It can understand the context of the conversation and respond accordingly, even when multiple people are talking at the same time.\\n\\n### 3\\\\. How does the AI moderator retrieve knowledge from different sources?\\n\\nThe AI moderator can retrieve knowledge from various sources, such as your YouTube channel, GitHub repository, and the internet. It uses a combination of knowledge retrieval techniques and online research tools to gather relevant information.\\n\\n### 4\\\\. Can the AI moderator generate reports and share AI trends?\\n\\nYes, the AI moderator can generate reports and share the latest AI trends. It can retrieve information from GitHub, filter out projects related to generative AI, and write reports to keep the community updated.\\n\\n### 5\\\\. How can I deploy the AI moderator on a cloud service?', metadata={'title': 'How to Build Agent workforce Tutorial- AI agent manages community 24/7', 'description': 'AI Agent,', 'ogTitle': 'How to Build Agent workforce Tutorial- AI agent manages community 24/7', 'ogDescription': 'AI Agent,', 'ogImage': 'https://assets-global.website-files.com/647a9c825f099afe643b5c78/65bee17260bcfa83d917651f_tiktok%20(6).jpg', 'sourceURL': 'https://www.ai-jason.com/learning-ai/ai-agent-tutorial-2'}),\n",
       " Document(page_content='To deploy the AI moderator on a cloud service, you can use platforms like Render. Simply upload your project to GitHub, create a new web service on Render, and configure the necessary environment variables. Render will handle the deployment and ensure your AI moderator stays active.\\n\\nRelated articles\\n----------------\\n\\n[Browse all articles](/)\\n\\n[AI Agent\\\\\\n\\\\\\n### How to reduce 78%+ of LLM Cost\\\\\\n\\\\\\n![How to reduce 78%+ of LLM Cost](https://assets-global.website-files.com/647a9c825f099afe643b5c78/65bedbda9969f366afdfad25_tiktok%20(1).jpg)](/learning-ai/how-to-reduce-llm-cost)\\n\\n[AI Agent\\\\\\n\\\\\\n### GPT5 unlocks LLM System 2 Thinking?\\\\\\n\\\\\\n![GPT5 unlocks LLM System 2 Thinking?\\\\\\n](https://assets-global.website-files.com/647a9c825f099afe643b5c78/65bedd7f060ee7802639f834_tiktok%20(2).jpg)](/learning-ai/gpt5-llm)', metadata={'title': 'How to Build Agent workforce Tutorial- AI agent manages community 24/7', 'description': 'AI Agent,', 'ogTitle': 'How to Build Agent workforce Tutorial- AI agent manages community 24/7', 'ogDescription': 'AI Agent,', 'ogImage': 'https://assets-global.website-files.com/647a9c825f099afe643b5c78/65bee17260bcfa83d917651f_tiktok%20(6).jpg', 'sourceURL': 'https://www.ai-jason.com/learning-ai/ai-agent-tutorial-2'}),\n",
       " Document(page_content=\"[AI Agent\\\\\\n\\\\\\n### Research agent 3.0 - Build a group of AI researchers - Step by Step Tutorial\\\\\\n\\\\\\n![Research agent 3.0 - Build a group of AI researchers - Step by Step Tutorial](https://assets-global.website-files.com/647a9c825f099afe643b5c78/65bedeabdecca18351fc45d0_tiktok%20(3).jpg)](/learning-ai/how-to-build-ai-agent-tutorial-3)\\n\\n### Need help building your AI apps?\\n\\nI can help you on building AI apps or give trainings\\n\\n[Tell me about your AI app ideas](mailto:jason.zhou.design@gmail.com)\\n\\n[\\ue82e](https://www.youtube.com/@AIJason-oc8wb)\\n[\\ue829](https://twitter.com/jasonzhou1993)\\n[\\ue819](https://www.linkedin.com/in/jasonzhoudesign/)\\n\\nAI Jason\\n\\n100K subscribers\\n\\n[AI agent manages community 24/7 - Build Agent workforce ep#1](https://www.youtube.com/watch?v=yhBiVrigWNI)\\n\\nAI Jason\\n\\nSearch\\n\\nInfo\\n\\nShopping\\n\\nTap to unmute\\n\\nIf playback doesn't begin shortly, try restarting your device.\\n\\nShare\\n\\nInclude playlist\\n\\nAn error occurred while retrieving sharing information. Please try again later.\\n\\nWatch later\", metadata={'title': 'How to Build Agent workforce Tutorial- AI agent manages community 24/7', 'description': 'AI Agent,', 'ogTitle': 'How to Build Agent workforce Tutorial- AI agent manages community 24/7', 'ogDescription': 'AI Agent,', 'ogImage': 'https://assets-global.website-files.com/647a9c825f099afe643b5c78/65bee17260bcfa83d917651f_tiktok%20(6).jpg', 'sourceURL': 'https://www.ai-jason.com/learning-ai/ai-agent-tutorial-2'}),\n",
       " Document(page_content='Share\\n\\nCopy link\\n\\nWatch on\\n\\n0:00\\n\\n/ â€¢Live\\n\\nâ€¢\\n\\n[](https://www.youtube.com/watch?v=yhBiVrigWNI \"Watch on YouTube\")', metadata={'title': 'How to Build Agent workforce Tutorial- AI agent manages community 24/7', 'description': 'AI Agent,', 'ogTitle': 'How to Build Agent workforce Tutorial- AI agent manages community 24/7', 'ogDescription': 'AI Agent,', 'ogImage': 'https://assets-global.website-files.com/647a9c825f099afe643b5c78/65bee17260bcfa83d917651f_tiktok%20(6).jpg', 'sourceURL': 'https://www.ai-jason.com/learning-ai/ai-agent-tutorial-2'})]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorstore = Chroma.from_documents(documents=filtered_docs, collection_name=\"rag-chromadb\", embedding=GPT4AllEmbeddings(),)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "#retriever to retrieve from the vectorstore\n",
    "retriever = vectorstore.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retriever grader will grade whether documents retrieved from the retriever are relevant to the query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_community.chat_models import ChatOllama\n",
    "from langchain_core.output_parsers import JsonOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(local_llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOllama(model_name=local_llm, format=\"json\", temperature=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"score\": \"no\"}{'score': 'no'}\n"
     ]
    }
   ],
   "source": [
    "### Retrieval Grader\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain import hub\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain.callbacks.manager import CallbackManager\n",
    "from langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler\n",
    "from langchain.llms import Ollama\n",
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "# LLM\n",
    "llm = Ollama(\n",
    "    model=\"llama3:latest\", callback_manager=CallbackManager([StreamingStdOutCallbackHandler()])\n",
    ")\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    template=\"\"\"<|begin_of_text|><|start_header_id|>system<|end_header_id|> You are a grader assessing relevance \n",
    "    of a retrieved document to a user question. If the document contains keywords related to the user question, \n",
    "    grade it as relevant. It does not need to be a stringent test. The goal is to filter out erroneous retrievals. \\n\n",
    "    Give a binary score 'yes' or 'no' score to indicate whether the document is relevant to the question. \\n\n",
    "    Provide the binary score as a JSON with a single key 'score' and no premable or explanation.\n",
    "     <|eot_id|><|start_header_id|>user<|end_header_id|>\n",
    "    Here is the retrieved document: \\n\\n {document} \\n\\n\n",
    "    Here is the user question: {question} \\n <|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
    "    \"\"\",\n",
    "    input_variables=[\"question\", \"document\"],\n",
    ")\n",
    "\n",
    "retrieval_grader = prompt | llm | JsonOutputParser()\n",
    "question = \"agent memory\"\n",
    "docs = retriever.invoke(question)\n",
    "doc_txt = docs[1].page_content\n",
    "print(retrieval_grader.invoke({\"question\": question, \"document\": doc_txt}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = PromptTemplate(\n",
    "    template=\"\"\"<|begin_of_text|><|start_header_id|>system<|end_header_id|> You are a grader assessing relevance \n",
    "    of a retrieved document to a user question. If the document contains keywords related to the user question, \n",
    "    grade it as relevant. It does not need to be a stringent test. The goal is to filter out erroneous retrievals. \\n\n",
    "    Give a binary score 'yes' or 'no' score to indicate whether the document is relevant to the question. \\n\n",
    "    Provide the binary score as a JSON with a single key 'score' and no premable or explanation.\n",
    "     <|eot_id|><|start_header_id|>user<|end_header_id|>\n",
    "    Here is the retrieved document: \\n\\n {document} \\n\\n\n",
    "    Here is the user question: {question} \\n <|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
    "    \"\"\",\n",
    "    input_variables=[\"question\", \"document\"],\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PromptTemplate(input_variables=['document', 'question'], template=\"<|begin_of_text|><|start_header_id|>system<|end_header_id|> You are a grader assessing relevance \\n    of a retrieved document to a user question. If the document contains keywords related to the user question, \\n    grade it as relevant. It does not need to be a stringent test. The goal is to filter out erroneous retrievals. \\n\\n    Give a binary score 'yes' or 'no' score to indicate whether the document is relevant to the question. \\n\\n    Provide the binary score as a JSON with a single key 'score' and no premable or explanation.\\n     <|eot_id|><|start_header_id|>user<|end_header_id|>\\n    Here is the retrieved document: \\n\\n {document} \\n\\n\\n    Here is the user question: {question} \\n <|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n    \")"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ollama(callbacks=<langchain_core.callbacks.manager.CallbackManager object at 0x35f933550>, model='llama3:latest')"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "retrieval_grader= prompt| llm| JsonOutputParser()\n",
    "question = \"How to reduce llm cost\"\n",
    "docs = retriever.invoke(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='A: It is recommended to monitor and optimize your LLM costs regularly, especially as your usage and user base grow. Keep track of cost patterns, identify areas for improvement, and implement cost optimization strategies accordingly.\\n\\n### Q: Can I reduce LLM costs without compromising performance?\\n\\nA: Yes, it is possible to reduce LLM costs without compromising performance. By carefully selecting the right models for specific tasks, optimizing agent memory, and using techniques like LLM Lingua, you can achieve cost savings while maintaining high performance and user experience.\\n\\n### Q: Are there any other cost optimization methods for LLM that I should be aware of?\\n\\nA: While the methods mentioned in this article are effective for reducing LLM costs, there may be other innovative approaches and techniques available. Stay updated with the latest research and developments in the field to discover new cost optimization methods.\\n\\nRelated articles\\n----------------\\n\\n[Browse all articles](/)', metadata={'description': 'AI Agent, Real cost of LLM', 'ogDescription': 'AI Agent, Real cost of LLM', 'ogImage': 'https://assets-global.website-files.com/647a9c825f099afe643b5c78/65bedbda9969f366afdfad25_tiktok%20(1).jpg', 'ogTitle': 'How to reduce 78%+ of LLM Cost', 'sourceURL': 'https://www.ai-jason.com/learning-ai/how-to-reduce-llm-cost', 'title': 'How to reduce 78%+ of LLM Cost'}),\n",
       " Document(page_content='By implementing these strategies, you can reduce LLM costs by up to 78% or more. Remember, reducing costs while maintaining performance and user experience is a critical skill for AI startups. Stay proactive and continuously optimize your LLM usage to maximize efficiency and profitability.\\n\\n\\u200d\\n\\nGet free HubSpot AI For Marketers Course: [https://clickhubspot.com/xut](https://clickhubspot.com/xut)\\n\\nðŸ”— Links', metadata={'description': 'AI Agent, Real cost of LLM', 'ogDescription': 'AI Agent, Real cost of LLM', 'ogImage': 'https://assets-global.website-files.com/647a9c825f099afe643b5c78/65bedbda9969f366afdfad25_tiktok%20(1).jpg', 'ogTitle': 'How to reduce 78%+ of LLM Cost', 'sourceURL': 'https://www.ai-jason.com/learning-ai/how-to-reduce-llm-cost', 'title': 'How to reduce 78%+ of LLM Cost'}),\n",
       " Document(page_content='One effective way to reduce LLM costs is to change the model you are using. Different models have different costs associated with them. For example, GPT-4 is the most powerful but also the most expensive model, while Mistro 7B is significantly cheaper. By using a smaller model for specific tasks and reserving the more expensive model for complex questions, you can achieve significant cost savings.\\n\\n![](https://assets-global.website-files.com/647a9c825f099afe643b5c78/65bedacac82767caefbdf0a0_1.jpg)\\n\\n2\\\\. Large Language Model Router\\n-------------------------------\\n\\nThe concept of a large language model router involves using a cascade of models to handle different types of questions. Cheaper models are used first, and if they are unable to provide a satisfactory answer, the question is passed on to a more expensive model. This approach leverages the significant cost difference between models and can result in substantial cost savings.', metadata={'description': 'AI Agent, Real cost of LLM', 'ogDescription': 'AI Agent, Real cost of LLM', 'ogImage': 'https://assets-global.website-files.com/647a9c825f099afe643b5c78/65bedbda9969f366afdfad25_tiktok%20(1).jpg', 'ogTitle': 'How to reduce 78%+ of LLM Cost', 'sourceURL': 'https://www.ai-jason.com/learning-ai/how-to-reduce-llm-cost', 'title': 'How to reduce 78%+ of LLM Cost'}),\n",
       " Document(page_content='*   Another video about details for LLM cost tracking: [https://www.youtube.com/watch?v=Alb2kjUzpZ8&ab\\\\_channel=LearnfromOpenSourcewithElie](https://www.youtube.com/watch?v=Alb2kjUzpZ8&ab_channel=LearnfromOpenSourcewithElie)', metadata={'description': 'AI Agent, Real cost of LLM', 'ogDescription': 'AI Agent, Real cost of LLM', 'ogImage': 'https://assets-global.website-files.com/647a9c825f099afe643b5c78/65bedbda9969f366afdfad25_tiktok%20(1).jpg', 'ogTitle': 'How to reduce 78%+ of LLM Cost', 'sourceURL': 'https://www.ai-jason.com/learning-ai/how-to-reduce-llm-cost', 'title': 'How to reduce 78%+ of LLM Cost'})]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_txt = docs[1].page_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'By implementing these strategies, you can reduce LLM costs by up to 78% or more. Remember, reducing costs while maintaining performance and user experience is a critical skill for AI startups. Stay proactive and continuously optimize your LLM usage to maximize efficiency and profitability.\\n\\n\\u200d\\n\\nGet free HubSpot AI For Marketers Course: [https://clickhubspot.com/xut](https://clickhubspot.com/xut)\\n\\nðŸ”— Links'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "retrieval_grader= prompt| llm| JsonOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PromptTemplate(input_variables=['document', 'question'], template=\"<|begin_of_text|><|start_header_id|>system<|end_header_id|> You are a grader assessing relevance \\n    of a retrieved document to a user question. If the document contains keywords related to the user question, \\n    grade it as relevant. It does not need to be a stringent test. The goal is to filter out erroneous retrievals. \\n\\n    Give a binary score 'yes' or 'no' score to indicate whether the document is relevant to the question. \\n\\n    Provide the binary score as a JSON with a single key 'score' and no premable or explanation.\\n     <|eot_id|><|start_header_id|>user<|end_header_id|>\\n    Here is the retrieved document: \\n\\n {document} \\n\\n\\n    Here is the user question: {question} \\n <|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n    \")\n",
       "| Ollama(callbacks=<langchain_core.callbacks.manager.CallbackManager object at 0x35f933550>, model='llama3:latest')\n",
       "| JsonOutputParser()"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retrieval_grader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ollama(callbacks=<langchain_core.callbacks.manager.CallbackManager object at 0x35f933550>, model='llama3:latest')"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('How to reduce llm cost',\n",
       " 'By implementing these strategies, you can reduce LLM costs by up to 78% or more. Remember, reducing costs while maintaining performance and user experience is a critical skill for AI startups. Stay proactive and continuously optimize your LLM usage to maximize efficiency and profitability.\\n\\n\\u200d\\n\\nGet free HubSpot AI For Marketers Course: [https://clickhubspot.com/xut](https://clickhubspot.com/xut)\\n\\nðŸ”— Links')"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question,doc_txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (base) genai@genais-MacBook-Pro ~ % ollama serve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"score\": \"yes\"}{'score': 'yes'}\n"
     ]
    }
   ],
   "source": [
    "print(retrieval_grader.invoke({\"question\":question, \"document\":doc_txt}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniconda/base/envs/crewai_test/lib/python3.11/site-packages/langchain_core/_api/deprecation.py:119: LangChainDeprecationWarning: The method `BaseLLM.__call__` was deprecated in langchain-core 0.1.7 and will be removed in 0.3.0. Use invoke instead.\n",
      "  warn_deprecated(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What a fascinating topic!\n",
      "\n",
      "The history of Artificial Intelligence (AI) is a long and winding road, spanning centuries. From ancient Greece to modern times, humans have been fascinated by the possibility of creating artificial beings that can think, learn, and act like humans. Here's a brief overview:\n",
      "\n",
      "**Ancient Times**\n",
      "\n",
      "* 500 BCE: The Greek myth of Talos, a bronze robot created by Hephaestus to guard the island of Crete, is considered one of the earliest recorded tales of AI.\n",
      "* 300 CE: In his book \"De Anima\" (On the Soul), Aristotle discussed the possibility of creating artificial beings that could think and move like humans.\n",
      "\n",
      "**The Dawn of Modern AI**\n",
      "\n",
      "* 1950s: The Dartmouth Summer Research Project on Artificial Intelligence, led by John McCarthy, Marvin Minsky, Nathaniel Rochester, and Claude Shannon, is often referred to as the birthplace of AI. This project aimed to create machines that could simulate human intelligence.\n",
      "* 1951: Alan Turing published \"Computing Machinery and Intelligence,\" a paper that proposed the Turing Test, a measure of a machine's ability to exhibit intelligent behavior equivalent to, or indistinguishable from, that of a human.\n",
      "* 1956: The first AI program, called Logical Theorist (now known as Logic Theorist), was developed by Allen Newell and Herbert Simon. This program could reason and solve problems using logical deduction.\n",
      "\n",
      "**The Golden Age**\n",
      "\n",
      "* 1960s: AI research accelerated with the development of:\n",
      "\t+ Machine learning algorithms (e.g., decision trees, Bayes' theorem)\n",
      "\t+ Rule-based systems (e.g., MYCIN, a pioneering expert system)\n",
      "\t+ Natural Language Processing (NLP) techniques\n",
      "\t+ Robotics and computer vision\n",
      "\n",
      "**The Dark Ages**\n",
      "\n",
      "* 1970s-1980s: AI research slowed due to:\n",
      "\t+ Lack of funding\n",
      "\t+ Limited computing power\n",
      "\t+ Focus on other areas of computer science, such as operating systems and networks\n",
      "\n",
      "**The Modern Era**\n",
      "\n",
      "* 1990s: AI research revived with the advent of:\n",
      "\t+ Machine learning frameworks (e.g., Backpropagation, Support Vector Machines)\n",
      "\t+ Deep learning algorithms (e.g., Convolutional Neural Networks, Recurrent Neural Networks)\n",
      "\t+ Increased computing power and data storage\n",
      "\t+ Growing demand for AI applications in industries like healthcare, finance, and education\n",
      "\n",
      "**Recent Advances**\n",
      "\n",
      "* 2000s: The rise of:\n",
      "\t+ Big Data analytics\n",
      "\t+ Cloud computing\n",
      "\t+ IoT (Internet of Things) devices\n",
      "\t+ Artificial General Intelligence (AGI) research\n",
      "* 2010s: The emergence of:\n",
      "\t+ Deep learning-based AI systems (e.g., AlphaGo, self-driving cars)\n",
      "\t+ Natural Language Processing advancements (e.g., language translation, chatbots)\n",
      "\t+ Edge AI and Federated Learning\n",
      "\n",
      "**The Future**\n",
      "\n",
      "* Ongoing research in areas like:\n",
      "\t+ Explainable AI\n",
      "\t+ Transfer learning\n",
      "\t+ Multimodal AI (combining vision, audio, text, etc.)\n",
      "\t+ Human-AI collaboration\n",
      "* Expected breakthroughs in areas like:\n",
      "\t+ AGI development\n",
      "\t+ Quantum AI\n",
      "\t+ Neuromorphic computing\n",
      "\n",
      "This brief history is just the tip of the iceberg. There's much more to explore and learn about the fascinating journey of Artificial Intelligence!"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'What a fascinating topic!\\n\\nThe history of Artificial Intelligence (AI) is a long and winding road, spanning centuries. From ancient Greece to modern times, humans have been fascinated by the possibility of creating artificial beings that can think, learn, and act like humans. Here\\'s a brief overview:\\n\\n**Ancient Times**\\n\\n* 500 BCE: The Greek myth of Talos, a bronze robot created by Hephaestus to guard the island of Crete, is considered one of the earliest recorded tales of AI.\\n* 300 CE: In his book \"De Anima\" (On the Soul), Aristotle discussed the possibility of creating artificial beings that could think and move like humans.\\n\\n**The Dawn of Modern AI**\\n\\n* 1950s: The Dartmouth Summer Research Project on Artificial Intelligence, led by John McCarthy, Marvin Minsky, Nathaniel Rochester, and Claude Shannon, is often referred to as the birthplace of AI. This project aimed to create machines that could simulate human intelligence.\\n* 1951: Alan Turing published \"Computing Machinery and Intelligence,\" a paper that proposed the Turing Test, a measure of a machine\\'s ability to exhibit intelligent behavior equivalent to, or indistinguishable from, that of a human.\\n* 1956: The first AI program, called Logical Theorist (now known as Logic Theorist), was developed by Allen Newell and Herbert Simon. This program could reason and solve problems using logical deduction.\\n\\n**The Golden Age**\\n\\n* 1960s: AI research accelerated with the development of:\\n\\t+ Machine learning algorithms (e.g., decision trees, Bayes\\' theorem)\\n\\t+ Rule-based systems (e.g., MYCIN, a pioneering expert system)\\n\\t+ Natural Language Processing (NLP) techniques\\n\\t+ Robotics and computer vision\\n\\n**The Dark Ages**\\n\\n* 1970s-1980s: AI research slowed due to:\\n\\t+ Lack of funding\\n\\t+ Limited computing power\\n\\t+ Focus on other areas of computer science, such as operating systems and networks\\n\\n**The Modern Era**\\n\\n* 1990s: AI research revived with the advent of:\\n\\t+ Machine learning frameworks (e.g., Backpropagation, Support Vector Machines)\\n\\t+ Deep learning algorithms (e.g., Convolutional Neural Networks, Recurrent Neural Networks)\\n\\t+ Increased computing power and data storage\\n\\t+ Growing demand for AI applications in industries like healthcare, finance, and education\\n\\n**Recent Advances**\\n\\n* 2000s: The rise of:\\n\\t+ Big Data analytics\\n\\t+ Cloud computing\\n\\t+ IoT (Internet of Things) devices\\n\\t+ Artificial General Intelligence (AGI) research\\n* 2010s: The emergence of:\\n\\t+ Deep learning-based AI systems (e.g., AlphaGo, self-driving cars)\\n\\t+ Natural Language Processing advancements (e.g., language translation, chatbots)\\n\\t+ Edge AI and Federated Learning\\n\\n**The Future**\\n\\n* Ongoing research in areas like:\\n\\t+ Explainable AI\\n\\t+ Transfer learning\\n\\t+ Multimodal AI (combining vision, audio, text, etc.)\\n\\t+ Human-AI collaboration\\n* Expected breakthroughs in areas like:\\n\\t+ AGI development\\n\\t+ Quantum AI\\n\\t+ Neuromorphic computing\\n\\nThis brief history is just the tip of the iceberg. There\\'s much more to explore and learn about the fascinating journey of Artificial Intelligence!'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.callbacks.manager import CallbackManager\n",
    "from langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler\n",
    "from langchain.llms import Ollama\n",
    "\n",
    "llm = Ollama(\n",
    "    model=\"llama3:latest\", callback_manager=CallbackManager([StreamingStdOutCallbackHandler()])\n",
    ")\n",
    "\n",
    "llm(\"Tell me about the history of AI\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = PromptTemplate(\n",
    "    template=\"\"\"<|begin_of_text|><|start_header_id|>system<|end_header_id|> You are a grader assessing relevance \n",
    "    of a retrieved document to a user question. If the document contains keywords related to the user question, \n",
    "    grade it as relevant. It does not need to be a stringent test. The goal is to filter out erroneous retrievals. \\n\n",
    "    Give a binary score 'yes' or 'no' score to indicate whether the document is relevant to the question. \\n\n",
    "    Provide the binary score as a JSON with a single key 'score' and no premable or explanation.\n",
    "    <|eot_id|><|start_header_id|>user<|end_header_id|>\n",
    "    Here is the retrieved document: \\n\\n {document} \\n\\n\n",
    "    Here is the user question: {question} \\n <|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
    "    \"\"\",\n",
    "    input_variables=[\"question\", \"document\"],\n",
    "    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = Ollama(\n",
    "    model=\"llama3:latest\", callback_manager=CallbackManager([StreamingStdOutCallbackHandler()])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "retrieval_grader= prompt| llm| JsonOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"score\": \"yes\"}{'score': 'yes'}\n"
     ]
    }
   ],
   "source": [
    "print(retrieval_grader.invoke({\"question\":question, \"document\":doc_txt}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"where to find iphone?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"score\": \"no\"}{'score': 'no'}\n"
     ]
    }
   ],
   "source": [
    "print(retrieval_grader.invoke({\"question\":question, \"document\":doc_txt}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Generate "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "from langchain import hub\n",
    "from langchain_core.output_parsers import StrOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = PromptTemplate(\n",
    "    template=\"\"\"<|begin_of_text|><|start_header_id|>system<|end_header_id|> \n",
    "    You are an assistant for question-answering tasks.\n",
    "    Use the following piece of retrieved context to answer the question.  If you do not know the answer, just say that you do not know.\n",
    "    Use three sentens maximum and keep the answer short.\n",
    "    <|eot_id|><|start_header_id|>user<|end_header_id|>\n",
    "    Question: \\n\\n {question} \\n\\n\n",
    "    Conext: {context} \\n <|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
    "    \"\"\",\n",
    "    input_variables=[\"question\", \"\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = Ollama(\n",
    "    model=\"llama3:latest\", callback_manager=CallbackManager([StreamingStdOutCallbackHandler()])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='A: It is recommended to monitor and optimize your LLM costs regularly, especially as your usage and user base grow. Keep track of cost patterns, identify areas for improvement, and implement cost optimization strategies accordingly.\\n\\n### Q: Can I reduce LLM costs without compromising performance?\\n\\nA: Yes, it is possible to reduce LLM costs without compromising performance. By carefully selecting the right models for specific tasks, optimizing agent memory, and using techniques like LLM Lingua, you can achieve cost savings while maintaining high performance and user experience.\\n\\n### Q: Are there any other cost optimization methods for LLM that I should be aware of?\\n\\nA: While the methods mentioned in this article are effective for reducing LLM costs, there may be other innovative approaches and techniques available. Stay updated with the latest research and developments in the field to discover new cost optimization methods.\\n\\nRelated articles\\n----------------\\n\\n[Browse all articles](/)', metadata={'description': 'AI Agent, Real cost of LLM', 'ogDescription': 'AI Agent, Real cost of LLM', 'ogImage': 'https://assets-global.website-files.com/647a9c825f099afe643b5c78/65bedbda9969f366afdfad25_tiktok%20(1).jpg', 'ogTitle': 'How to reduce 78%+ of LLM Cost', 'sourceURL': 'https://www.ai-jason.com/learning-ai/how-to-reduce-llm-cost', 'title': 'How to reduce 78%+ of LLM Cost'}),\n",
       " Document(page_content='By implementing these strategies, you can reduce LLM costs by up to 78% or more. Remember, reducing costs while maintaining performance and user experience is a critical skill for AI startups. Stay proactive and continuously optimize your LLM usage to maximize efficiency and profitability.\\n\\n\\u200d\\n\\nGet free HubSpot AI For Marketers Course: [https://clickhubspot.com/xut](https://clickhubspot.com/xut)\\n\\nðŸ”— Links', metadata={'description': 'AI Agent, Real cost of LLM', 'ogDescription': 'AI Agent, Real cost of LLM', 'ogImage': 'https://assets-global.website-files.com/647a9c825f099afe643b5c78/65bedbda9969f366afdfad25_tiktok%20(1).jpg', 'ogTitle': 'How to reduce 78%+ of LLM Cost', 'sourceURL': 'https://www.ai-jason.com/learning-ai/how-to-reduce-llm-cost', 'title': 'How to reduce 78%+ of LLM Cost'}),\n",
       " Document(page_content='One effective way to reduce LLM costs is to change the model you are using. Different models have different costs associated with them. For example, GPT-4 is the most powerful but also the most expensive model, while Mistro 7B is significantly cheaper. By using a smaller model for specific tasks and reserving the more expensive model for complex questions, you can achieve significant cost savings.\\n\\n![](https://assets-global.website-files.com/647a9c825f099afe643b5c78/65bedacac82767caefbdf0a0_1.jpg)\\n\\n2\\\\. Large Language Model Router\\n-------------------------------\\n\\nThe concept of a large language model router involves using a cascade of models to handle different types of questions. Cheaper models are used first, and if they are unable to provide a satisfactory answer, the question is passed on to a more expensive model. This approach leverages the significant cost difference between models and can result in substantial cost savings.', metadata={'description': 'AI Agent, Real cost of LLM', 'ogDescription': 'AI Agent, Real cost of LLM', 'ogImage': 'https://assets-global.website-files.com/647a9c825f099afe643b5c78/65bedbda9969f366afdfad25_tiktok%20(1).jpg', 'ogTitle': 'How to reduce 78%+ of LLM Cost', 'sourceURL': 'https://www.ai-jason.com/learning-ai/how-to-reduce-llm-cost', 'title': 'How to reduce 78%+ of LLM Cost'}),\n",
       " Document(page_content='*   Another video about details for LLM cost tracking: [https://www.youtube.com/watch?v=Alb2kjUzpZ8&ab\\\\_channel=LearnfromOpenSourcewithElie](https://www.youtube.com/watch?v=Alb2kjUzpZ8&ab_channel=LearnfromOpenSourcewithElie)', metadata={'description': 'AI Agent, Real cost of LLM', 'ogDescription': 'AI Agent, Real cost of LLM', 'ogImage': 'https://assets-global.website-files.com/647a9c825f099afe643b5c78/65bedbda9969f366afdfad25_tiktok%20(1).jpg', 'ogTitle': 'How to reduce 78%+ of LLM Cost', 'sourceURL': 'https://www.ai-jason.com/learning-ai/how-to-reduce-llm-cost', 'title': 'How to reduce 78%+ of LLM Cost'})]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join([doc.page_content for doc in docs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "rag_chain= prompt| llm| StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"How to reduce llm cost\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'function' object has no attribute 'invoke'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[86], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m docs \u001b[38;5;241m=\u001b[39m \u001b[43mretriever\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m(question)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'function' object has no attribute 'invoke'"
     ]
    }
   ],
   "source": [
    "docs = retriever.invoke(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To reduce LLM cost, it is recommended to monitor and optimize your costs regularly. You can achieve cost savings by carefully selecting the right models for specific tasks, optimizing agent memory, and using techniques like LLM Lingua. Additionally, you can consider changing the model you are using or implementing a large language model router that uses a cascade of models to handle different types of questions."
     ]
    }
   ],
   "source": [
    "generation= rag_chain.invoke({\"context\":docs, \"question\":question})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To reduce LLM cost, it is recommended to monitor and optimize your costs regularly. You can achieve cost savings by carefully selecting the right models for specific tasks, optimizing agent memory, and using techniques like LLM Lingua. Additionally, you can consider changing the model you are using or implementing a large language model router that uses a cascade of models to handle different types of questions.\n"
     ]
    }
   ],
   "source": [
    "print(generation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"TAVILY_API_KEY\"] = \"tvly-\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "\n",
    "web_search_tool = TavilySearchResults(k=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"score\": \"yes\"}"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'score': 'yes'}"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# LLM\n",
    "llm = Ollama(\n",
    "    model=\"llama3:latest\", callback_manager=CallbackManager([StreamingStdOutCallbackHandler()])\n",
    ")\n",
    "\n",
    "# Prompt\n",
    "prompt = PromptTemplate(\n",
    "    template=\"\"\"<|begin_of_text|><|start_header_id|>system<|end_header_id|> You are a grader assessing whether an \n",
    "    answer is useful to resolve a question. Give a binary score 'yes' or 'no' to indicate whether the answer is \n",
    "    useful to resolve a question. Provide the binary score as a JSON with a single key 'score' and no preamble or explanation.\n",
    "     <|eot_id|><|start_header_id|>user<|end_header_id|> Here is the answer:\n",
    "    \\n ------- \\n\n",
    "    {generation} \n",
    "    \\n ------- \\n\n",
    "    Here is the question: {question} <|eot_id|><|start_header_id|>assistant<|end_header_id|>\"\"\",\n",
    "    input_variables=[\"generation\", \"question\"],\n",
    ")\n",
    "\n",
    "answer_grader = prompt | llm | JsonOutputParser()\n",
    "answer_grader.invoke({\"question\": question, \"generation\": generation})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check whether answer is actually correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = Ollama(\n",
    "    model=\"llama3:latest\", callback_manager=CallbackManager([StreamingStdOutCallbackHandler()])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = PromptTemplate(\n",
    "    template=\"\"\"<|begin_of_text|><|start_header_id|>system<|end_header_id|> \n",
    "    You are a grader assessing whether and answer is grounded in / supported by set of facts.  Give a binary score 'yes' or 'no' score to \n",
    "    indicate whether the answer is grounded in / supported by set of facts. Provide a binary score as JSON with a single key 'score' and no \n",
    "    preamble or explination. \\n\n",
    "    <|eot_id|><|start_header_id|>user<|end_header_id|>\n",
    "    Here are the facts:\n",
    "    \\n ----------- \\n\n",
    "    {document}\n",
    "     \\n ----------- \\n\n",
    "     Here is the answer: \\n\\n {generation} \\n\\n\n",
    "    \\n <|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
    "    \"\"\",\n",
    "    input_variables=[\"generation\", \"document\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "hallucination_grader= prompt| llm| JsonOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"score\": \"yes\"}"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'score': 'yes'}"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hallucination_grader.invoke({\"generation\":generation, \"document\":docs})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "#LangGraph Setup states and nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing_extensions import TypedDict\n",
    "from typing import List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "### State"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# State is value that we want to share across all different steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"datasource\": \"vectorstore\"}{'datasource': 'vectorstore'}\n"
     ]
    }
   ],
   "source": [
    "llm = Ollama(\n",
    "    model=\"llama3:latest\", callback_manager=CallbackManager([StreamingStdOutCallbackHandler()])\n",
    ")\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    template=\"\"\"<|begin_of_text|><|start_header_id|>system<|end_header_id|> You are an expert at routing a \n",
    "    user question to a vectorstore or web search. Use the vectorstore for questions on LLM  agents, \n",
    "    prompt engineering, and adversarial attacks. You do not need to be stringent with the keywords \n",
    "    in the question related to these topics. Otherwise, use web-search. Give a binary choice 'web_search' \n",
    "    or 'vectorstore' based on the question. Return the a JSON with a single key 'datasource' and \n",
    "    no premable or explanation. Question to route: {question} <|eot_id|><|start_header_id|>assistant<|end_header_id|>\"\"\",\n",
    "    input_variables=[\"question\"],\n",
    ")\n",
    "\n",
    "question_router = prompt | llm | JsonOutputParser()\n",
    "question = \"llm agent memory\"\n",
    "docs = retriever.invoke(question)\n",
    "doc_txt = docs[1].page_content\n",
    "print(question_router.invoke({\"question\": question}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "At 'generate' node, 'grade_generation_v_documents_and_question' branch found unknown target 'END'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[89], line 198\u001b[0m\n\u001b[1;32m    187\u001b[0m workflow\u001b[38;5;241m.\u001b[39madd_conditional_edges(\n\u001b[1;32m    188\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgenerate\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    189\u001b[0m     grade_generation_v_documents_and_question,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    194\u001b[0m     },\n\u001b[1;32m    195\u001b[0m )\n\u001b[1;32m    197\u001b[0m \u001b[38;5;66;03m#Compile\u001b[39;00m\n\u001b[0;32m--> 198\u001b[0m app \u001b[38;5;241m=\u001b[39m \u001b[43mworkflow\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompile\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    199\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpprint\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m pprint\n\u001b[1;32m    200\u001b[0m inputs \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mquestion\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mHow to save llm cost?\u001b[39m\u001b[38;5;124m\"\u001b[39m}\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/crewai_test/lib/python3.11/site-packages/langgraph/graph/state.py:134\u001b[0m, in \u001b[0;36mStateGraph.compile\u001b[0;34m(self, checkpointer, interrupt_before, interrupt_after, debug)\u001b[0m\n\u001b[1;32m    131\u001b[0m interrupt_after \u001b[38;5;241m=\u001b[39m interrupt_after \u001b[38;5;129;01mor\u001b[39;00m []\n\u001b[1;32m    133\u001b[0m \u001b[38;5;66;03m# validate the graph\u001b[39;00m\n\u001b[0;32m--> 134\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalidate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    135\u001b[0m \u001b[43m    \u001b[49m\u001b[43minterrupt\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43minterrupt_before\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43minterrupt_before\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m!=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m*\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    136\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43minterrupt_after\u001b[49m\n\u001b[1;32m    137\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43minterrupt_after\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m!=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m*\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[1;32m    138\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m    139\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    141\u001b[0m \u001b[38;5;66;03m# prepare output channels\u001b[39;00m\n\u001b[1;32m    142\u001b[0m state_keys \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchannels)\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/crewai_test/lib/python3.11/site-packages/langgraph/graph/graph.py:272\u001b[0m, in \u001b[0;36mGraph.validate\u001b[0;34m(self, interrupt)\u001b[0m\n\u001b[1;32m    270\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m end \u001b[38;5;129;01min\u001b[39;00m branch\u001b[38;5;241m.\u001b[39mends\u001b[38;5;241m.\u001b[39mvalues():\n\u001b[1;32m    271\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m end \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnodes \u001b[38;5;129;01mand\u001b[39;00m end \u001b[38;5;241m!=\u001b[39m END:\n\u001b[0;32m--> 272\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    273\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAt \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mstart\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m node, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcond\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m branch found unknown target \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mend\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    274\u001b[0m             )\n\u001b[1;32m    275\u001b[0m         all_targets\u001b[38;5;241m.\u001b[39madd(end)\n\u001b[1;32m    276\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;31mValueError\u001b[0m: At 'generate' node, 'grade_generation_v_documents_and_question' branch found unknown target 'END'"
     ]
    }
   ],
   "source": [
    "class GraphState(TypedDict):\n",
    "    \"\"\" Repressents the current state of the graph. \"\"\"\n",
    "    question: str # question user asked\n",
    "    generation: str # answer generated by LLM\n",
    "    web_search: str # result of web search\n",
    "    documents: List[str] # document retrieved from retriever\n",
    "    \n",
    "### Nodes\n",
    "from langchain.schema import Document\n",
    "def retriever(state):\n",
    "    \"\"\"\n",
    "    Retrieve documents from the vector store.\n",
    "    \"\"\"\n",
    "    print(\"---RETRIEVE---\")\n",
    "    question = state[\"question\"]\n",
    "    # Retrieval\n",
    "    documents = retriever.invoke(question)\n",
    "    #Retrieve documents from the vector store and overwrite global state.\n",
    "    return {\"document\": documents, \"question\": question}\n",
    "    \n",
    "def generate(state):\n",
    "    \"\"\"\n",
    "    Generate answer using RAG on retrieved documents\n",
    "    \"\"\"\n",
    "    print(\"---GENERATE---\")\n",
    "    question = state[\"question\"]\n",
    "    documents = state[\"documents\"]\n",
    "\n",
    "    # RAG generation\n",
    "    generation = rag_chain.invoke({\"context\": documents, \"question\": question})\n",
    "    return {\"documents\": documents, \"question\": question, \"generation\": generation}\n",
    "\n",
    "\n",
    "    \n",
    "def grade_documents(state):\n",
    "    \"\"\"\n",
    "    Determines whether the retrieved documents are relevant to the question\n",
    "    If any document is not relevant, we will set a flag to run web search\n",
    "    \"\"\"\n",
    "\n",
    "    print(\"---CHECK DOCUMENT RELEVANCE TO QUESTION---\")\n",
    "    question = state[\"question\"]\n",
    "    documents = state[\"documents\"]\n",
    "\n",
    "    # Score each doc\n",
    "    filtered_docs = []\n",
    "    web_search = \"No\"\n",
    "    for d in documents:\n",
    "        score = retrieval_grader.invoke(\n",
    "            {\"question\": question, \"document\": d.page_content}\n",
    "        )\n",
    "        grade = score[\"score\"]\n",
    "        # Document relevant\n",
    "        if grade.lower() == \"yes\":\n",
    "            print(\"---GRADE: DOCUMENT RELEVANT---\")\n",
    "            filtered_docs.append(d)\n",
    "        # Document not relevant\n",
    "        else:\n",
    "            print(\"---GRADE: DOCUMENT NOT RELEVANT---\")\n",
    "            # We do not include the document in filtered_docs\n",
    "            # We set a flag to indicate that we want to run web search\n",
    "            web_search = \"Yes\"\n",
    "            continue\n",
    "    return {\"documents\": filtered_docs, \"question\": question, \"web_search\": web_search}\n",
    "\n",
    "\n",
    "def web_search(state):\n",
    "    \"\"\"\n",
    "    web search based on question\n",
    "    \"\"\"\n",
    "    print(\"---WEB SEARCH---\")\n",
    "    question = state[\"question\"]\n",
    "    documents = state[\"documents\"]\n",
    "\n",
    "    # Web search\n",
    "    docs = web_search_tool.invoke({\"query\": question})\n",
    "    web_results = \"\\n\".join([d[\"content\"] for d in docs])\n",
    "    web_results = Document(page_content=web_results)\n",
    "    if documents is not None:\n",
    "        documents.append(web_results)\n",
    "    else:\n",
    "        documents = [web_results]\n",
    "    return {\"documents\": documents, \"question\": question}\n",
    "\n",
    "\n",
    " #Conditional edge\n",
    "\n",
    "def route_question(state):\n",
    "    \"\"\"\n",
    "    Route question to web search or RAG.\n",
    "    \"\"\"\n",
    "\n",
    "    print(\"---ROUTE QUESTION---\")\n",
    "    question = state[\"question\"]\n",
    "    print(question)\n",
    "    source = question_router.invoke({\"question\": question})\n",
    "    print(source)\n",
    "    print(source[\"datasource\"])\n",
    "    if source[\"datasource\"] == \"web_search\":\n",
    "        print(\"---ROUTE QUESTION TO WEB SEARCH---\")\n",
    "        return \"websearch\"\n",
    "    elif source[\"datasource\"] == \"vectorstore\":\n",
    "        print(\"---ROUTE QUESTION TO RAG---\")\n",
    "        return \"vectorstore\"\n",
    "def decide_to_generate(state):\n",
    "    \"\"\"\n",
    "    Determine whether to generate answer or add web search\n",
    "    \"\"\"\n",
    "    print(\"---ASSESS GRADED DOCUMENTS---\")\n",
    "    question = state[\"question\"]\n",
    "    web_search = state[\"web_search\"]\n",
    "    filtered_documents = state[\"documents\"]\n",
    "\n",
    "    if web_search == \"Yes\":\n",
    "        # All documents have been filtered check_relevance\n",
    "        # We will re-generate a new query\n",
    "        print(\n",
    "            \"---DECISION: ALL DOCUMENTS ARE NOT RELEVANT TO QUESTION, INCLUDE WEB SEARCH---\"\n",
    "        )\n",
    "        return \"websearch\"\n",
    "    else:\n",
    "        # We have relevant documents, so generate answer\n",
    "        print(\"---DECISION: GENERATE---\")\n",
    "        return \"generate\"\n",
    "\n",
    "def grade_generation_v_documents_and_question(state):\n",
    "    \"\"\"\n",
    "    Determines whether the generation is grounded in the document and answers question.\n",
    "\n",
    "    Args:\n",
    "        state (dict): The current graph state\n",
    "\n",
    "    Returns:\n",
    "        str: Decision for next node to call\n",
    "    \"\"\"\n",
    "\n",
    "    print(\"---CHECK HALLUCINATIONS---\")\n",
    "    question = state[\"question\"]\n",
    "    documents = state[\"documents\"]\n",
    "    generation = state[\"generation\"]\n",
    "\n",
    "    score = hallucination_grader.invoke(\n",
    "        {\"documents\": documents, \"generation\": generation}\n",
    "    )\n",
    "    grade = score[\"score\"]\n",
    "\n",
    "    # Check hallucination\n",
    "    if grade == \"yes\":\n",
    "        print(\"---DECISION: GENERATION IS GROUNDED IN DOCUMENTS---\")\n",
    "        # Check question-answering\n",
    "        print(\"---GRADE GENERATION vs QUESTION---\")\n",
    "        score = answer_grader.invoke({\"question\": question, \"generation\": generation})\n",
    "        grade = score[\"score\"]\n",
    "        if grade == \"yes\":\n",
    "            print(\"---DECISION: GENERATION ADDRESSES QUESTION---\")\n",
    "            return \"useful\"\n",
    "        else:\n",
    "            print(\"---DECISION: GENERATION DOES NOT ADDRESS QUESTION---\")\n",
    "            return \"not useful\"\n",
    "    else:\n",
    "        pprint(\"---DECISION: GENERATION IS NOT GROUNDED IN DOCUMENTS, RE-TRY---\")\n",
    "        return \"not supported\"\n",
    "    \n",
    "from langgraph.graph import END, StateGraph\n",
    "workflow = StateGraph(GraphState)\n",
    "    \n",
    "# Add all nodes \n",
    "workflow.add_node(\"websearch\", web_search)\n",
    "workflow.add_node(\"retriever\", retriever)\n",
    "workflow.add_node(\"grade_documents\", grade_documents)\n",
    "workflow.add_node(\"generate\", generate)\n",
    "\n",
    "#Build graph\n",
    "\n",
    "workflow.set_entry_point(\"retriever\")\n",
    "workflow.add_edge(\"retriever\", \"grade_documents\")\n",
    "workflow.add_conditional_edges(\n",
    "    \"grade_documents\", \n",
    "    decide_to_generate,\n",
    "    {\n",
    "        \"websearch\": \"websearch\",\n",
    "        \"generate\": \"generate\"\n",
    "    },\n",
    ")\n",
    "\n",
    "workflow.add_edge(\"websearch\", \"generate\")\n",
    "workflow.add_conditional_edges(\n",
    "    \"generate\",\n",
    "    grade_generation_v_documents_and_question,\n",
    "    {\n",
    "        \"not_supported\": \"generate\",\n",
    "        \"useful\": \"END\",\n",
    "        \"not useful\": \"websearch\"\n",
    "    },\n",
    ")\n",
    "\n",
    "#Compile\n",
    "app = workflow.compile()\n",
    "from pprint import pprint\n",
    "inputs = {\"question\": \"How to save llm cost?\"}\n",
    "for outputs in app.stream(inputs):\n",
    "    for k, v in outputs.items():\n",
    "        pprint(f\"{k}: {v}\")\n",
    "print(v[\"generation\"])\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'score': 'yes'}"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Hallucination Grader\n",
    "\n",
    "# LLM\n",
    "llm = Ollama(model=local_llm, format=\"json\", temperature=0)\n",
    "\n",
    "# Prompt\n",
    "prompt = PromptTemplate(\n",
    "    template=\"\"\" <|begin_of_text|><|start_header_id|>system<|end_header_id|> You are a grader assessing whether \n",
    "    an answer is grounded in / supported by a set of facts. Give a binary 'yes' or 'no' score to indicate \n",
    "    whether the answer is grounded in / supported by a set of facts. Provide the binary score as a JSON with a \n",
    "    single key 'score' and no preamble or explanation. <|eot_id|><|start_header_id|>user<|end_header_id|>\n",
    "    Here are the facts:\n",
    "    \\n ------- \\n\n",
    "    {documents} \n",
    "    \\n ------- \\n\n",
    "    Here is the answer: {generation}  <|eot_id|><|start_header_id|>assistant<|end_header_id|>\"\"\",\n",
    "    input_variables=[\"generation\", \"documents\"],\n",
    ")\n",
    "\n",
    "hallucination_grader = prompt | llm | JsonOutputParser()\n",
    "hallucination_grader.invoke({\"documents\": docs, \"generation\": generation})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing_extensions import TypedDict\n",
    "from typing import List\n",
    "\n",
    "### State\n",
    "\n",
    "\n",
    "class GraphState(TypedDict):\n",
    "    \"\"\"\n",
    "    Represents the state of our graph.\n",
    "\n",
    "    Attributes:\n",
    "        question: question\n",
    "        generation: LLM generation\n",
    "        web_search: whether to add search\n",
    "        documents: list of documents\n",
    "    \"\"\"\n",
    "\n",
    "    question: str\n",
    "    generation: str\n",
    "    web_search: str\n",
    "    documents: List[str]\n",
    "\n",
    "\n",
    "from langchain.schema import Document\n",
    "\n",
    "### Nodes\n",
    "\n",
    "\n",
    "def retrieve(state):\n",
    "    \"\"\"\n",
    "    Retrieve documents from vectorstore\n",
    "\n",
    "    Args:\n",
    "        state (dict): The current graph state\n",
    "\n",
    "    Returns:\n",
    "        state (dict): New key added to state, documents, that contains retrieved documents\n",
    "    \"\"\"\n",
    "    print(\"---RETRIEVE---\")\n",
    "    question = state[\"question\"]\n",
    "\n",
    "    # Retrieval\n",
    "    documents = retriever.invoke(question)\n",
    "    return {\"documents\": documents, \"question\": question}\n",
    "\n",
    "\n",
    "def generate(state):\n",
    "    \"\"\"\n",
    "    Generate answer using RAG on retrieved documents\n",
    "\n",
    "    Args:\n",
    "        state (dict): The current graph state\n",
    "\n",
    "    Returns:\n",
    "        state (dict): New key added to state, generation, that contains LLM generation\n",
    "    \"\"\"\n",
    "    print(\"---GENERATE---\")\n",
    "    question = state[\"question\"]\n",
    "    documents = state[\"documents\"]\n",
    "\n",
    "    # RAG generation\n",
    "    generation = rag_chain.invoke({\"context\": documents, \"question\": question})\n",
    "    return {\"documents\": documents, \"question\": question, \"generation\": generation}\n",
    "\n",
    "\n",
    "def grade_documents(state):\n",
    "    \"\"\"\n",
    "    Determines whether the retrieved documents are relevant to the question\n",
    "    If any document is not relevant, we will set a flag to run web search\n",
    "\n",
    "    Args:\n",
    "        state (dict): The current graph state\n",
    "\n",
    "    Returns:\n",
    "        state (dict): Filtered out irrelevant documents and updated web_search state\n",
    "    \"\"\"\n",
    "\n",
    "    print(\"---CHECK DOCUMENT RELEVANCE TO QUESTION---\")\n",
    "    question = state[\"question\"]\n",
    "    documents = state[\"documents\"]\n",
    "\n",
    "    # Score each doc\n",
    "    filtered_docs = []\n",
    "    web_search = \"No\"\n",
    "    for d in documents:\n",
    "        score = retrieval_grader.invoke(\n",
    "            {\"question\": question, \"document\": d.page_content}\n",
    "        )\n",
    "        grade = score[\"score\"]\n",
    "        # Document relevant\n",
    "        if grade.lower() == \"yes\":\n",
    "            print(\"---GRADE: DOCUMENT RELEVANT---\")\n",
    "            filtered_docs.append(d)\n",
    "        # Document not relevant\n",
    "        else:\n",
    "            print(\"---GRADE: DOCUMENT NOT RELEVANT---\")\n",
    "            # We do not include the document in filtered_docs\n",
    "            # We set a flag to indicate that we want to run web search\n",
    "            web_search = \"Yes\"\n",
    "            continue\n",
    "    return {\"documents\": filtered_docs, \"question\": question, \"web_search\": web_search}\n",
    "\n",
    "\n",
    "def web_search(state):\n",
    "    \"\"\"\n",
    "    Web search based based on the question\n",
    "\n",
    "    Args:\n",
    "        state (dict): The current graph state\n",
    "\n",
    "    Returns:\n",
    "        state (dict): Appended web results to documents\n",
    "    \"\"\"\n",
    "\n",
    "    print(\"---WEB SEARCH---\")\n",
    "    question = state[\"question\"]\n",
    "    documents = state[\"documents\"]\n",
    "\n",
    "    # Web search\n",
    "    docs = web_search_tool.invoke({\"query\": question})\n",
    "    web_results = \"\\n\".join([d[\"content\"] for d in docs])\n",
    "    web_results = Document(page_content=web_results)\n",
    "    if documents is not None:\n",
    "        documents.append(web_results)\n",
    "    else:\n",
    "        documents = [web_results]\n",
    "    return {\"documents\": documents, \"question\": question}\n",
    "\n",
    "\n",
    "### Conditional edge\n",
    "\n",
    "\n",
    "def route_question(state):\n",
    "    \"\"\"\n",
    "    Route question to web search or RAG.\n",
    "\n",
    "    Args:\n",
    "        state (dict): The current graph state\n",
    "\n",
    "    Returns:\n",
    "        str: Next node to call\n",
    "    \"\"\"\n",
    "\n",
    "    print(\"---ROUTE QUESTION---\")\n",
    "    question = state[\"question\"]\n",
    "    print(question)\n",
    "    source = question_router.invoke({\"question\": question})\n",
    "    print(source)\n",
    "    print(source[\"datasource\"])\n",
    "    if source[\"datasource\"] == \"web_search\":\n",
    "        print(\"---ROUTE QUESTION TO WEB SEARCH---\")\n",
    "        return \"websearch\"\n",
    "    elif source[\"datasource\"] == \"vectorstore\":\n",
    "        print(\"---ROUTE QUESTION TO RAG---\")\n",
    "        return \"vectorstore\"\n",
    "\n",
    "\n",
    "def decide_to_generate(state):\n",
    "    \"\"\"\n",
    "    Determines whether to generate an answer, or add web search\n",
    "\n",
    "    Args:\n",
    "        state (dict): The current graph state\n",
    "\n",
    "    Returns:\n",
    "        str: Binary decision for next node to call\n",
    "    \"\"\"\n",
    "\n",
    "    print(\"---ASSESS GRADED DOCUMENTS---\")\n",
    "    question = state[\"question\"]\n",
    "    web_search = state[\"web_search\"]\n",
    "    filtered_documents = state[\"documents\"]\n",
    "\n",
    "    if web_search == \"Yes\":\n",
    "        # All documents have been filtered check_relevance\n",
    "        # We will re-generate a new query\n",
    "        print(\n",
    "            \"---DECISION: ALL DOCUMENTS ARE NOT RELEVANT TO QUESTION, INCLUDE WEB SEARCH---\"\n",
    "        )\n",
    "        return \"websearch\"\n",
    "    else:\n",
    "        # We have relevant documents, so generate answer\n",
    "        print(\"---DECISION: GENERATE---\")\n",
    "        return \"generate\"\n",
    "\n",
    "\n",
    "### Conditional edge\n",
    "\n",
    "\n",
    "def grade_generation_v_documents_and_question(state):\n",
    "    \"\"\"\n",
    "    Determines whether the generation is grounded in the document and answers question.\n",
    "\n",
    "    Args:\n",
    "        state (dict): The current graph state\n",
    "\n",
    "    Returns:\n",
    "        str: Decision for next node to call\n",
    "    \"\"\"\n",
    "\n",
    "    print(\"---CHECK HALLUCINATIONS---\")\n",
    "    question = state[\"question\"]\n",
    "    documents = state[\"documents\"]\n",
    "    generation = state[\"generation\"]\n",
    "\n",
    "    score = hallucination_grader.invoke(\n",
    "        {\"documents\": documents, \"generation\": generation}\n",
    "    )\n",
    "    grade = score[\"score\"]\n",
    "\n",
    "    # Check hallucination\n",
    "    if grade == \"yes\":\n",
    "        print(\"---DECISION: GENERATION IS GROUNDED IN DOCUMENTS---\")\n",
    "        # Check question-answering\n",
    "        print(\"---GRADE GENERATION vs QUESTION---\")\n",
    "        score = answer_grader.invoke({\"question\": question, \"generation\": generation})\n",
    "        grade = score[\"score\"]\n",
    "        if grade == \"yes\":\n",
    "            print(\"---DECISION: GENERATION ADDRESSES QUESTION---\")\n",
    "            return \"useful\"\n",
    "        else:\n",
    "            print(\"---DECISION: GENERATION DOES NOT ADDRESS QUESTION---\")\n",
    "            return \"not useful\"\n",
    "    else:\n",
    "        pprint(\"---DECISION: GENERATION IS NOT GROUNDED IN DOCUMENTS, RE-TRY---\")\n",
    "        return \"not supported\"\n",
    "\n",
    "\n",
    "from langgraph.graph import END, StateGraph\n",
    "\n",
    "workflow = StateGraph(GraphState)\n",
    "\n",
    "# Define the nodes\n",
    "workflow.add_node(\"websearch\", web_search)  # web search\n",
    "workflow.add_node(\"retrieve\", retrieve)  # retrieve\n",
    "workflow.add_node(\"grade_documents\", grade_documents)  # grade documents\n",
    "workflow.add_node(\"generate\", generate)  # generatae\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build graph\n",
    "workflow.set_conditional_entry_point(\n",
    "    route_question,\n",
    "    {\n",
    "        \"websearch\": \"websearch\",\n",
    "        \"vectorstore\": \"retrieve\",\n",
    "    },\n",
    ")\n",
    "\n",
    "workflow.add_edge(\"retrieve\", \"grade_documents\")\n",
    "workflow.add_conditional_edges(\n",
    "    \"grade_documents\",\n",
    "    decide_to_generate,\n",
    "    {\n",
    "        \"websearch\": \"websearch\",\n",
    "        \"generate\": \"generate\",\n",
    "    },\n",
    ")\n",
    "workflow.add_edge(\"websearch\", \"generate\")\n",
    "workflow.add_conditional_edges(\n",
    "    \"generate\",\n",
    "    grade_generation_v_documents_and_question,\n",
    "    {\n",
    "        \"not supported\": \"generate\",\n",
    "        \"useful\": END,\n",
    "        \"not useful\": \"websearch\",\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = vectorstore.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---ROUTE QUESTION---\n",
      "What are the types of agent memory?\n",
      "{\"datasource\": \"vectorstore\"}{'datasource': 'vectorstore'}\n",
      "vectorstore\n",
      "---ROUTE QUESTION TO RAG---\n",
      "---RETRIEVE---\n",
      "'Finished running: retrieve:'\n",
      "---CHECK DOCUMENT RELEVANCE TO QUESTION---\n",
      "{\"score\": \"yes\"}---GRADE: DOCUMENT RELEVANT---\n",
      "{\"score\": \"no\"}---GRADE: DOCUMENT NOT RELEVANT---\n",
      "{\"score\": \"no\"}---GRADE: DOCUMENT NOT RELEVANT---\n",
      "{\"score\": \"no\"}---GRADE: DOCUMENT NOT RELEVANT---\n",
      "---ASSESS GRADED DOCUMENTS---\n",
      "---DECISION: ALL DOCUMENTS ARE NOT RELEVANT TO QUESTION, INCLUDE WEB SEARCH---\n",
      "'Finished running: grade_documents:'\n",
      "---WEB SEARCH---\n",
      "'Finished running: websearch:'\n",
      "---GENERATE---\n",
      "Based on the provided context, there are different types of agent memory mentioned, including:\n",
      "\n",
      "1. Data Structures and Algorithms: This type of memory refers to the way an agent stores and retrieves information.\n",
      "2. Memory can be defined as the resource or store used to acquire, store, retain, and later retrieve information.\n",
      "\n",
      "These are general categories that encompass various types of memory, but a more detailed classification is not provided in this context.---CHECK HALLUCINATIONS---\n",
      "---DECISION: GENERATION IS GROUNDED IN DOCUMENTS---\n",
      "---GRADE GENERATION vs QUESTION---\n",
      "{\"score\": \"yes\"}---DECISION: GENERATION ADDRESSES QUESTION---\n",
      "'Finished running: generate:'\n",
      "('Based on the provided context, there are different types of agent memory '\n",
      " 'mentioned, including:\\n'\n",
      " '\\n'\n",
      " '1. Data Structures and Algorithms: This type of memory refers to the way an '\n",
      " 'agent stores and retrieves information.\\n'\n",
      " '2. Memory can be defined as the resource or store used to acquire, store, '\n",
      " 'retain, and later retrieve information.\\n'\n",
      " '\\n'\n",
      " 'These are general categories that encompass various types of memory, but a '\n",
      " 'more detailed classification is not provided in this context.')\n"
     ]
    }
   ],
   "source": [
    "# Compile\n",
    "app = workflow.compile()\n",
    "\n",
    "# Test\n",
    "from pprint import pprint\n",
    "\n",
    "inputs = {\"question\": \"What are the types of agent memory?\"}\n",
    "for output in app.stream(inputs):\n",
    "    for key, value in output.items():\n",
    "        pprint(f\"Finished running: {key}:\")\n",
    "pprint(value[\"generation\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "crewai_test",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
